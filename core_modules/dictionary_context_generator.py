#!/usr/bin/env python3
"""
æ•°æ®å­—å…¸é©±åŠ¨çš„ä¸Šä¸‹æ–‡æ–‡ä»¶ç”Ÿæˆå™¨
ç›´æ¥å¯¼å…¥ä¸šåŠ¡æ•°æ®ï¼Œåˆ©ç”¨æ•°æ®å­—å…¸ç”Ÿæˆä¸°å¯Œçš„ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶
"""

import os
import sqlite3
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
import json
import requests
from datetime import datetime
from pathlib import Path

class DictionaryContextGenerator:
    """æ•°æ®å­—å…¸é©±åŠ¨çš„ä¸Šä¸‹æ–‡æ–‡ä»¶ç”Ÿæˆå™¨"""

    def __init__(self, output_db_path: str, api_key: Optional[str] = None):
        self.output_db_path = output_db_path
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        self.dictionary_files = []  # æ•°æ®å­—å…¸æ–‡ä»¶ä¿¡æ¯
        self.business_data_files = []  # ä¸šåŠ¡æ•°æ®æ–‡ä»¶ä¿¡æ¯
        self.imported_tables = []  # å¯¼å…¥çš„è¡¨ä¿¡æ¯
        self.business_terms = {}  # ä¸šåŠ¡æœ¯è¯­è¯å…¸
        self.field_descriptions = {}  # å­—æ®µæè¿°æ˜ å°„
        self.query_scope_rules = []  # æŸ¥è¯¢èŒƒå›´è§„åˆ™
        self.database_description = {}  # æ•°æ®åº“æè¿°ä¿¡æ¯
        self.table_name_config = self._load_table_name_config()  # è¡¨åæ˜ å°„é…ç½®

    def _load_table_name_config(self) -> Dict[str, Any]:
        """åŠ è½½è¡¨åæ˜ å°„é…ç½®"""
        try:
            config_path = "configs/table_name_mappings.json"
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                print(f"âš ï¸ è¡¨åæ˜ å°„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return {}
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è¡¨åæ˜ å°„é…ç½®å¤±è´¥: {e}")
            return {}

    def generate_database_with_context(self, data_dir: str) -> Dict[str, Any]:
        """æ•°æ®å­—å…¸é©±åŠ¨çš„æ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆå·¥ä½œæµ"""
        print(f"ğŸ—ï¸ å¼€å§‹æ•°æ®å­—å…¸é©±åŠ¨çš„æ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆ...")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        print(f"ğŸ“ è¾“å‡ºæ•°æ®åº“: {self.output_db_path}")

        try:
            # æ­¥éª¤1ï¼šç›´æ¥å¯¼å…¥ä¸šåŠ¡æ•°æ®åˆ°æ•°æ®åº“ï¼ˆä¿æŒåŸå§‹ç»“æ„ï¼‰
            self._step1_import_business_data_directly(data_dir)

            # æ­¥éª¤2ï¼šè¯»å–å’Œåˆ†ææ•°æ®å­—å…¸
            self._step2_analyze_data_dictionaries(data_dir)

            # æ­¥éª¤3ï¼šä½¿ç”¨LLMç”Ÿæˆä¸šåŠ¡æœ¯è¯­è¯å…¸
            self._step3_generate_business_terms_with_llm()

            # æ­¥éª¤4ï¼šç”Ÿæˆå®Œæ•´çš„æ•°æ®åº“ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶
            self._step4_generate_context_configuration()

            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_comprehensive_report()
            print(f"âœ… æ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæˆï¼")
            print(f"   ğŸ“Š å¯¼å…¥è¡¨æ•°: {len(self.imported_tables)}")
            print(f"   ğŸ“š ä¸šåŠ¡æœ¯è¯­: {len(self.business_terms)}")
            print(f"   ğŸ“‹ å­—æ®µæè¿°: {len(self.field_descriptions)}")
            print(f"   ğŸ“ æŸ¥è¯¢è§„åˆ™: {len(self.query_scope_rules)}")

            return report

        except Exception as e:
            print(f"âŒ æ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _step1_import_business_data_directly(self, data_dir: str):
        """æ­¥éª¤1ï¼šç›´æ¥å¯¼å…¥ä¸šåŠ¡æ•°æ®åˆ°æ•°æ®åº“ï¼ˆä¿æŒåŸå§‹ç»“æ„ï¼‰"""
        print(f"\nğŸ“Š æ­¥éª¤1ï¼šç›´æ¥å¯¼å…¥ä¸šåŠ¡æ•°æ®ï¼ˆä¿æŒåŸå§‹ç»“æ„ï¼‰")

        # æŸ¥æ‰¾ä¸šåŠ¡æ•°æ®æ–‡ä»¶ï¼ˆéæ•°æ®å­—å…¸æ–‡ä»¶ï¼‰
        business_files = []
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.endswith(('.xlsx', '.xls', '.csv')) and 'æ•°æ®å­—å…¸' not in file:
                    file_path = os.path.join(root, file)
                    business_files.append(file_path)

        print(f"ğŸ“Š å‘ç° {len(business_files)} ä¸ªä¸šåŠ¡æ•°æ®æ–‡ä»¶")

        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        conn = sqlite3.connect(self.output_db_path)

        try:
            for business_file in business_files:
                file_name = os.path.basename(business_file)
                print(f"ğŸ“Š å¯¼å…¥ä¸šåŠ¡æ•°æ®: {file_name}")

                try:
                    # è¯»å–æ•°æ®æ–‡ä»¶
                    if file_name.endswith('.csv'):
                        df = pd.read_csv(business_file)
                    else:
                        df = pd.read_excel(business_file)

                    # ç”Ÿæˆè¡¨åï¼ˆåŸºäºæ–‡ä»¶åï¼‰
                    table_name = self._generate_table_name_from_filename(file_name)

                    # ç›´æ¥å¯¼å…¥åˆ°æ•°æ®åº“ï¼Œä¿æŒåŸå§‹å­—æ®µåå’Œç»“æ„
                    df.fillna('').to_sql(table_name, conn, if_exists='replace', index=False)

                    # è®°å½•å¯¼å…¥ä¿¡æ¯
                    table_info = {
                        'table_name': table_name,
                        'source_file': file_name,
                        'source_path': business_file,
                        'rows': len(df),
                        'columns': len(df.columns),
                        'column_names': list(df.columns),
                        'chinese_name': self._extract_chinese_name_from_filename(file_name)
                    }
                    self.imported_tables.append(table_info)
                    self.business_data_files.append(table_info)

                    print(f"âœ… å¯¼å…¥æˆåŠŸ: {table_name} ({len(df)}è¡Œ, {len(df.columns)}åˆ—)")

                except Exception as e:
                    print(f"âŒ å¯¼å…¥å¤±è´¥: {file_name} - {e}")

        finally:
            conn.close()

        print(f"ğŸ“Š ä¸šåŠ¡æ•°æ®å¯¼å…¥å®Œæˆï¼Œå…±å¯¼å…¥ {len(self.imported_tables)} ä¸ªè¡¨")

    def _generate_table_name_from_filename(self, filename: str) -> str:
        """æ™ºèƒ½ç”Ÿæˆæ ‡å‡†åŒ–çš„è¡¨å - æ”¯æŒå¤šç§é“¶è¡Œæœºæ„å’Œå‘½åè§„èŒƒ"""
        try:
            # 1. é¦–å…ˆå°è¯•é…ç½®æ–‡ä»¶æ˜ å°„
            table_name = self._try_config_mapping(filename)
            if table_name:
                print(f"ğŸ“‹ ä½¿ç”¨é…ç½®æ˜ å°„: {filename} -> {table_name}")
                return table_name

            # 2. å°è¯•LLMæ™ºèƒ½æ¨æ–­
            table_name = self._try_llm_table_name_inference(filename)
            if table_name:
                print(f"ğŸ§  LLMæ¨æ–­è¡¨å: {filename} -> {table_name}")
                return table_name

            # 3. ä½¿ç”¨æ¨¡å¼åŒ¹é…ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            table_name = self._try_pattern_matching(filename)
            if table_name:
                print(f"ğŸ” æ¨¡å¼åŒ¹é…: {filename} -> {table_name}")
                return table_name

            # 4. å›é€€åˆ°é€šç”¨å‘½åè§„åˆ™
            fallback_name = self._generate_fallback_table_name(filename)
            print(f"âš¡ ä½¿ç”¨å›é€€æ–¹æ¡ˆ: {filename} -> {fallback_name}")
            return fallback_name

        except Exception as e:
            print(f"âš ï¸ è¡¨åç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ: {e}")
            return self._generate_fallback_table_name(filename)

    def _try_config_mapping(self, filename: str) -> Optional[str]:
        """å°è¯•ä½¿ç”¨é…ç½®æ–‡ä»¶æ˜ å°„"""
        try:
            if not self.table_name_config:
                return None

            # æ¸…ç†æ–‡ä»¶åç”¨äºåŒ¹é…
            clean_filename = filename.replace('.xlsx', '').replace('.xls', '').replace('.csv', '')

            # ç²¾ç¡®åŒ¹é…
            exact_matches = self.table_name_config.get('exact_matches', {})
            if clean_filename in exact_matches:
                return exact_matches[clean_filename]

            # æ¨¡å¼åŒ¹é…
            pattern_matches = self.table_name_config.get('pattern_matches', {})
            for pattern, table_name in pattern_matches.items():
                if pattern in clean_filename:
                    return table_name

            return None

        except Exception as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶æ˜ å°„å¤±è´¥: {e}")
            return None

    def _try_llm_table_name_inference(self, filename: str) -> Optional[str]:
        """ä½¿ç”¨LLMæ™ºèƒ½æ¨æ–­è¡¨å"""
        if not self.api_key:
            return None

        try:
            # æ„å»ºLLMæç¤ºè¯
            prompt = f"""
è¯·åŸºäºæ–‡ä»¶åç”Ÿæˆä¸€ä¸ªæ ‡å‡†çš„è‹±æ–‡æ•°æ®åº“è¡¨åã€‚

æ–‡ä»¶å: {filename}

è¦æ±‚:
1. è¡¨åå¿…é¡»æ˜¯è‹±æ–‡ï¼Œä½¿ç”¨ä¸‹åˆ’çº¿åˆ†éš”
2. è¡¨ååº”è¯¥åæ˜ æ–‡ä»¶çš„ä¸šåŠ¡å«ä¹‰
3. éµå¾ªæ•°æ®åº“å‘½åè§„èŒƒï¼ˆå°å†™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
4. é•¿åº¦ä¸è¶…è¿‡50ä¸ªå­—ç¬¦
5. åªè¿”å›è¡¨åï¼Œä¸è¦å…¶ä»–æ–‡å­—

ç¤ºä¾‹:
- "å®¢æˆ·ä¿¡æ¯è¡¨.xlsx" -> "customer_info"
- "LOAN_CONTRACT_DATA.xlsx" -> "loan_contract_data"
- "å­˜æ¬¾ä½™é¢ç»Ÿè®¡.xlsx" -> "deposit_balance"

è¯·ä¸ºä»¥ä¸‹æ–‡ä»¶ç”Ÿæˆè¡¨å: {filename}
"""

            response = self._call_llm_api(prompt, max_retries=2)
            if response:
                # æ¸…ç†LLMå“åº”ï¼Œæå–è¡¨å
                table_name = self._clean_llm_table_name_response(response)
                if table_name and self._validate_table_name(table_name):
                    return table_name

            return None

        except Exception as e:
            print(f"âš ï¸ LLMè¡¨åæ¨æ–­å¤±è´¥: {e}")
            return None

    def _try_pattern_matching(self, filename: str) -> Optional[str]:
        """ä½¿ç”¨é…ç½®æ–‡ä»¶çš„æ¨¡å¼åŒ¹é…ï¼ˆä»…é™é…ç½®æ–‡ä»¶ä¸­å®šä¹‰çš„æ¨¡å¼ï¼‰"""
        if not self.table_name_config:
            return None

        name = filename.replace('.xlsx', '').replace('.xls', '').replace('.csv', '')

        # åªä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­å®šä¹‰çš„æ¨¡å¼åŒ¹é…
        pattern_matches = self.table_name_config.get('pattern_matches', {})
        for pattern, table_name in pattern_matches.items():
            if pattern in name:
                return table_name

        return None

    def _generate_fallback_table_name(self, filename: str) -> str:
        """ç”Ÿæˆç®€æ´çš„å›é€€è¡¨å"""
        import re

        # ç§»é™¤æ‰©å±•å
        name = filename.replace('.xlsx', '').replace('.xls', '').replace('.csv', '')

        # æå–è‹±æ–‡éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        english_part = ''.join(c for c in name if ord(c) < 128)
        if english_part:
            name = english_part

        # æ¸…ç†å’Œæ ‡å‡†åŒ–
        clean_name = re.sub(r'[^\w]', '_', name.lower())
        clean_name = re.sub(r'_+', '_', clean_name).strip('_')

        # é™åˆ¶é•¿åº¦å¹¶ç¡®ä¿æœ‰æ•ˆ
        if len(clean_name) > 50:
            clean_name = clean_name[:50].rstrip('_')

        return clean_name if clean_name and clean_name[0].isalpha() else 'data_table'

    def _clean_llm_table_name_response(self, response: str) -> Optional[str]:
        """æ¸…ç†LLMå“åº”ï¼Œæå–è¡¨å"""
        if not response:
            return None

        # ç§»é™¤å¤šä½™çš„æ–‡å­—ï¼Œåªä¿ç•™è¡¨å
        lines = response.strip().split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith(('è¯·', 'è¡¨å', 'å»ºè®®', 'æ¨è')):
                # ç§»é™¤å¯èƒ½çš„å‰ç¼€
                line = line.replace('è¡¨å:', '').replace('Table name:', '').strip()
                if self._validate_table_name(line):
                    return line

        return None

    def _validate_table_name(self, table_name: str) -> bool:
        """éªŒè¯è¡¨åæ˜¯å¦ç¬¦åˆè§„èŒƒ"""
        import re

        if not table_name:
            return False

        # æ£€æŸ¥é•¿åº¦
        if len(table_name) > 50:
            return False

        # æ£€æŸ¥å­—ç¬¦è§„èŒƒï¼ˆåªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        if not re.match(r'^[a-z][a-z0-9_]*$', table_name):
            return False

        # æ£€æŸ¥æ˜¯å¦ä»¥å­—æ¯å¼€å¤´
        if not table_name[0].isalpha():
            return False

        return True

    def _extract_chinese_name_from_filename(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–ä¸­æ–‡åç§°"""
        name = filename.replace('.xlsx', '').replace('.xls', '').replace('.csv', '')

        # æå–ä¸­æ–‡éƒ¨åˆ†
        chinese_chars = ''.join(c for c in name if '\u4e00' <= c <= '\u9fff' or c in 'ï¼ˆï¼‰()ï¼Œ,ã€‚.')

        if chinese_chars:
            return chinese_chars.strip('ï¼ˆï¼‰(),ï¼Œã€‚.')
        else:
            return name

    def _step2_analyze_data_dictionaries(self, data_dir: str):
        """æ­¥éª¤2ï¼šè¯»å–å’Œåˆ†ææ•°æ®å­—å…¸"""
        print(f"\nğŸ“š æ­¥éª¤2ï¼šè¯»å–å’Œåˆ†ææ•°æ®å­—å…¸")

        # æŸ¥æ‰¾æ•°æ®å­—å…¸æ–‡ä»¶
        dict_files = []
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.endswith(('.xlsx', '.xls')) and 'æ•°æ®å­—å…¸' in file:
                    file_path = os.path.join(root, file)
                    dict_files.append(file_path)

        print(f"ğŸ“š å‘ç° {len(dict_files)} ä¸ªæ•°æ®å­—å…¸æ–‡ä»¶")

        for dict_file in dict_files:
            file_name = os.path.basename(dict_file)
            print(f"ğŸ“š åˆ†ææ•°æ®å­—å…¸: {file_name}")

            try:
                # è¯»å–æ•°æ®å­—å…¸Excelæ–‡ä»¶
                df = pd.read_excel(dict_file)

                # æå–è¡¨åï¼ˆä»æ–‡ä»¶åï¼‰
                table_name = self._extract_table_name_from_dict_file(file_name)

                # åˆ†æå­—å…¸å†…å®¹ï¼Œæå–å­—æ®µä¿¡æ¯
                field_info = self._extract_field_info_from_dictionary(df, table_name)

                # å­˜å‚¨æ•°æ®å­—å…¸ä¿¡æ¯
                dict_info = {
                    'file_name': file_name,
                    'file_path': dict_file,
                    'table_name': table_name,
                    'field_info': field_info,
                    'raw_data': df
                }
                self.dictionary_files.append(dict_info)

                print(f"âœ… åˆ†æå®Œæˆ: {file_name} - {len(field_info)} ä¸ªå­—æ®µå®šä¹‰")

            except Exception as e:
                print(f"âŒ åˆ†æå¤±è´¥: {file_name} - {e}")

        print(f"ğŸ“š æ•°æ®å­—å…¸åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(self.dictionary_files)} ä¸ªå­—å…¸æ–‡ä»¶")

    def _extract_table_name_from_dict_file(self, dict_file_name: str) -> str:
        """ä»æ•°æ®å­—å…¸æ–‡ä»¶åæ™ºèƒ½æå–è¡¨å"""
        # æ¸…ç†æ–‡ä»¶å
        name = dict_file_name.replace('æ•°æ®å­—å…¸-', '').replace('.xlsx', '').replace('.xls', '')

        # ä½¿ç”¨å·²æœ‰çš„æ™ºèƒ½è¡¨åç”Ÿæˆæ–¹æ³•
        return self._generate_table_name_from_filename(name + '.xlsx')

    def _extract_field_info_from_dictionary(self, df: pd.DataFrame, table_name: str) -> List[Dict]:
        """ä»æ•°æ®å­—å…¸DataFrameä¸­æå–å­—æ®µä¿¡æ¯"""
        field_info = []

        # å°è¯•è¯†åˆ«æ•°æ®å­—å…¸çš„ç»“æ„
        # å¸¸è§çš„åˆ—åï¼šå­—æ®µåã€å­—æ®µä¸­æ–‡åã€æ•°æ®ç±»å‹ã€é•¿åº¦ã€æ˜¯å¦ä¸»é”®ã€æ˜¯å¦å¯ä¸ºç©ºã€æ³¨é‡Š/è¯´æ˜

        for index, row in df.iterrows():
            try:
                # è·³è¿‡è¡¨å¤´è¡Œ
                if index == 0 and any(keyword in str(row.iloc[0]) for keyword in ['å­—æ®µ', 'åç§°', 'ç±»å‹']):
                    continue

                # æå–å­—æ®µä¿¡æ¯
                field_data = {}

                # å°è¯•ä»ä¸åŒåˆ—æå–ä¿¡æ¯
                for col_idx, value in enumerate(row):
                    if pd.isna(value):
                        continue

                    value_str = str(value).strip()
                    if not value_str:
                        continue

                    # æ ¹æ®åˆ—çš„ä½ç½®å’Œå†…å®¹æ¨æ–­å­—æ®µä¿¡æ¯
                    if col_idx == 0 and value_str:  # ç¬¬ä¸€åˆ—é€šå¸¸æ˜¯å­—æ®µå
                        field_data['field_name'] = value_str
                    elif col_idx == 1 and value_str:  # ç¬¬äºŒåˆ—é€šå¸¸æ˜¯ä¸­æ–‡åæˆ–è¯´æ˜
                        field_data['chinese_name'] = value_str
                    elif col_idx == 2 and value_str:  # ç¬¬ä¸‰åˆ—é€šå¸¸æ˜¯æ•°æ®ç±»å‹
                        field_data['data_type'] = value_str
                    elif col_idx == 3 and value_str:  # ç¬¬å››åˆ—å¯èƒ½æ˜¯é•¿åº¦
                        field_data['length'] = value_str
                    elif 'è¯´æ˜' in str(df.columns[col_idx]) or 'æ³¨é‡Š' in str(df.columns[col_idx]):
                        field_data['description'] = value_str

                # å¦‚æœæå–åˆ°äº†å­—æ®µåï¼Œåˆ™æ·»åŠ åˆ°åˆ—è¡¨
                if 'field_name' in field_data and field_data['field_name']:
                    field_data['table_name'] = table_name
                    field_info.append(field_data)

            except Exception as e:
                print(f"âš ï¸ è§£æå­—æ®µä¿¡æ¯æ—¶å‡ºé”™ (è¡Œ {index}): {e}")
                continue

        return field_info

    def _step3_generate_business_terms_with_llm(self):
        """æ­¥éª¤3ï¼šä½¿ç”¨LLMç”Ÿæˆä¸šåŠ¡æœ¯è¯­è¯å…¸"""
        print(f"\nğŸ§  æ­¥éª¤3ï¼šä½¿ç”¨LLMç”Ÿæˆä¸šåŠ¡æœ¯è¯­è¯å…¸")

        if not self.api_key:
            print("âš ï¸ æœªé…ç½®APIå¯†é’¥ï¼Œè·³è¿‡LLMåˆ†æ")
            self._generate_basic_business_terms()
            return

        if not self.dictionary_files:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å­—å…¸æ–‡ä»¶ï¼Œè·³è¿‡ä¸šåŠ¡æœ¯è¯­ç”Ÿæˆ")
            return

        # ä¸ºæ¯ä¸ªæ•°æ®å­—å…¸ç”Ÿæˆä¸šåŠ¡æœ¯è¯­
        for dict_info in self.dictionary_files:
            table_name = dict_info['table_name']
            field_info = dict_info['field_info']

            print(f"ğŸ§  ä¸ºè¡¨ {table_name} ç”Ÿæˆä¸šåŠ¡æœ¯è¯­...")

            # æ„å»ºLLMæç¤ºè¯
            field_summary = ""
            for field in field_info:
                field_name = field.get('field_name', '')
                chinese_name = field.get('chinese_name', '')
                description = field.get('description', '')
                data_type = field.get('data_type', '')

                field_summary += f"- {field_name}: {chinese_name}"
                if description:
                    field_summary += f" ({description})"
                if data_type:
                    field_summary += f" [{data_type}]"
                field_summary += "\n"

            prompt = f"""
è¯·åŸºäºä»¥ä¸‹é“¶è¡Œä¸šåŠ¡æ•°æ®å­—å…¸ï¼Œç”Ÿæˆä¸šåŠ¡æœ¯è¯­è¯å…¸å’Œå­—æ®µæè¿°ã€‚

è¡¨å: {table_name}
å­—æ®µä¿¡æ¯:
{field_summary}

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
  "business_terms": {{
    "ä¸­æ–‡ä¸šåŠ¡æœ¯è¯­1": "å¯¹åº”çš„è‹±æ–‡å­—æ®µåæˆ–è®¡ç®—è§„åˆ™",
    "ä¸­æ–‡ä¸šåŠ¡æœ¯è¯­2": "å¯¹åº”çš„è‹±æ–‡å­—æ®µåæˆ–è®¡ç®—è§„åˆ™"
  }},
  "field_descriptions": {{
    "å­—æ®µå1": {{
      "chinese_name": "ä¸­æ–‡åç§°",
      "business_meaning": "ä¸šåŠ¡å«ä¹‰è¯´æ˜",
      "calculation_rule": "è®¡ç®—è§„åˆ™ï¼ˆå¦‚æœé€‚ç”¨ï¼‰",
      "data_source": "æ•°æ®æ¥æºè¯´æ˜"
    }}
  }},
  "query_rules": [
    {{
      "rule_type": "èŒƒå›´é™åˆ¶|æ•°æ®è¿‡æ»¤|ä¸šåŠ¡è§„åˆ™",
      "description": "è§„åˆ™æè¿°",
      "condition": "å…·ä½“æ¡ä»¶"
    }}
  ]
}}

è¦æ±‚ï¼š
1. ä¸šåŠ¡æœ¯è¯­è¦åŒ…å«é“¶è¡Œå¸¸ç”¨æœ¯è¯­ï¼ˆå¦‚ï¼šå¯¹å…¬æœ‰æ•ˆæˆ·ã€ä¸è‰¯è´·æ¬¾ä½™é¢ç­‰ï¼‰
2. å­—æ®µæè¿°è¦è¯¦ç»†è¯´æ˜ä¸šåŠ¡å«ä¹‰
3. æŸ¥è¯¢è§„åˆ™è¦åŸºäºé“¶è¡Œä¸šåŠ¡é€»è¾‘
4. åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—
"""

            try:
                response = self._call_llm_api(prompt)
                if response:
                    result = json.loads(self._clean_llm_response(response))

                    # åˆå¹¶ä¸šåŠ¡æœ¯è¯­
                    if 'business_terms' in result:
                        self.business_terms.update(result['business_terms'])

                    # åˆå¹¶å­—æ®µæè¿°
                    if 'field_descriptions' in result:
                        for field_name, desc in result['field_descriptions'].items():
                            self.field_descriptions[f"{table_name}.{field_name}"] = desc

                    # åˆå¹¶æŸ¥è¯¢è§„åˆ™
                    if 'query_rules' in result:
                        for rule in result['query_rules']:
                            rule['table_name'] = table_name
                            self.query_scope_rules.append(rule)

                    print(f"âœ… ä¸šåŠ¡æœ¯è¯­ç”ŸæˆæˆåŠŸ: {table_name}")
                else:
                    print(f"âŒ ä¸šåŠ¡æœ¯è¯­ç”Ÿæˆå¤±è´¥: {table_name}")

            except Exception as e:
                print(f"âŒ ä¸šåŠ¡æœ¯è¯­ç”Ÿæˆå¼‚å¸¸: {table_name} - {e}")

        print(f"ğŸ§  ä¸šåŠ¡æœ¯è¯­ç”Ÿæˆå®Œæˆ")
        print(f"   ğŸ“š ä¸šåŠ¡æœ¯è¯­: {len(self.business_terms)} ä¸ª")
        print(f"   ğŸ“‹ å­—æ®µæè¿°: {len(self.field_descriptions)} ä¸ª")
        print(f"   ğŸ“ æŸ¥è¯¢è§„åˆ™: {len(self.query_scope_rules)} ä¸ª")

    def _generate_basic_business_terms(self):
        """ç”ŸæˆåŸºç¡€ä¸šåŠ¡æœ¯è¯­ï¼ˆä¸ä½¿ç”¨LLMï¼‰"""
        print("ğŸ”§ ç”ŸæˆåŸºç¡€ä¸šåŠ¡æœ¯è¯­ï¼ˆæ— LLMæ¨¡å¼ï¼‰")

        # åŸºç¡€é“¶è¡Œä¸šåŠ¡æœ¯è¯­æ˜ å°„
        basic_terms = {
            "å¯¹å…¬æœ‰æ•ˆæˆ·": "å®¢æˆ·å¹³å‡æ—¥å­˜æ¬¾ä½™é¢ >= 100000",
            "ä¸è‰¯è´·æ¬¾ä½™é¢": "è´·æ¬¾åˆ†ç±»ä¸ºæ¬¡çº§ã€å¯ç–‘ã€æŸå¤±çš„è´·æ¬¾ä½™é¢",
            "å®¢æˆ·å·": "customer_id",
            "å®¢æˆ·åç§°": "customer_name",
            "åˆåŒå·": "contract_id",
            "è´·æ¬¾ä½™é¢": "loan_balance",
            "å­˜æ¬¾ä½™é¢": "deposit_balance",
            "æœºæ„åç§°": "institution_name",
            "å¼€æˆ·æ—¥æœŸ": "account_date",
            "åˆ°æœŸæ—¥æœŸ": "maturity_date"
        }

        self.business_terms.update(basic_terms)

        # åŸºç¡€å­—æ®µæè¿°
        for table_info in self.business_data_files:
            table_name = table_info['table_name']
            for col_name in table_info['column_names']:
                self.field_descriptions[f"{table_name}.{col_name}"] = {
                    "chinese_name": col_name,
                    "business_meaning": f"{table_name}è¡¨çš„{col_name}å­—æ®µ",
                    "calculation_rule": "ç›´æ¥å­—æ®µå€¼",
                    "data_source": f"æ¥æºäº{table_info['source_file']}"
                }

    def _step4_generate_context_configuration(self):
        """æ­¥éª¤4ï¼šç”Ÿæˆå®Œæ•´çš„æ•°æ®åº“ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶"""
        print(f"\nğŸ“„ æ­¥éª¤4ï¼šç”Ÿæˆæ•°æ®åº“ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶")

        # ç”Ÿæˆæ•°æ®åº“æè¿°ä¿¡æ¯
        self._generate_database_description()

        # æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡é…ç½®
        context_config = {
            "database_info": {
                "name": os.path.basename(self.output_db_path).replace('.db', ''),
                "path": self.output_db_path,
                "type": "sqlite",
                "created_at": datetime.now().isoformat(),
                "description": "åŸºäºæ•°æ®å­—å…¸ç”Ÿæˆçš„é“¶è¡Œä¸šåŠ¡æ•°æ®åº“",
                "source": "dictionary_context_generator"
            },
            "tables": self._generate_tables_config(),
            "business_terms": self.business_terms,
            "field_descriptions": self.field_descriptions,
            "query_scope_rules": self.query_scope_rules,
            "database_description": self.database_description
        }

        # ä¿å­˜ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶
        self._save_context_configuration(context_config)

        print(f"ğŸ“„ ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ")

    def _generate_database_description(self):
        """æ™ºèƒ½ç”Ÿæˆæ•°æ®åº“æè¿°ä¿¡æ¯"""
        # åŸºäºå®é™…å¯¼å…¥çš„è¡¨åŠ¨æ€ç”Ÿæˆä¸šåŠ¡é¢†åŸŸ
        key_business_areas = set()

        for table in self.imported_tables:
            category = self._categorize_table(table['table_name'])
            key_business_areas.add(category)

        self.database_description = {
            "purpose": "åŸºäºæ•°æ®å­—å…¸ç”Ÿæˆçš„ä¸šåŠ¡æ•°æ®åˆ†ææ•°æ®åº“",
            "domain": "banking",
            "tables_count": len(self.imported_tables),
            "total_rows": sum(table['rows'] for table in self.imported_tables),
            "data_sources": [table['source_file'] for table in self.imported_tables],
            "table_relationships": self._infer_table_relationships(),
            "key_business_areas": list(key_business_areas)
        }

    def _generate_tables_config(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¡¨é…ç½®ä¿¡æ¯"""
        tables_config = {}

        for table_info in self.imported_tables:
            table_name = table_info['table_name']

            # æŸ¥æ‰¾å¯¹åº”çš„æ•°æ®å­—å…¸ä¿¡æ¯
            dict_info = None
            for dict_file in self.dictionary_files:
                if dict_file['table_name'] == table_name:
                    dict_info = dict_file
                    break

            table_config = {
                "chinese_name": table_info['chinese_name'],
                "description": self._get_table_description(table_name),
                "row_count": table_info['rows'],
                "column_count": table_info['columns'],
                "source_file": table_info['source_file'],
                "columns": table_info['column_names'],
                "primary_keys": self._identify_primary_keys(table_name, table_info['column_names']),
                "business_category": self._categorize_table(table_name),
                "data_dictionary_available": dict_info is not None
            }

            if dict_info:
                table_config["dictionary_fields"] = len(dict_info['field_info'])
                table_config["dictionary_source"] = dict_info['file_name']

            tables_config[table_name] = table_config

        return tables_config

    def _infer_table_relationships(self) -> List[Dict]:
        """ä½¿ç”¨LLMæ™ºèƒ½æ¨æ–­è¡¨ä¹‹é—´çš„å…³ç³»"""
        try:
            relationships = []

            if len(self.imported_tables) < 2:
                return relationships

            # ä½¿ç”¨LLMåˆ†æè¡¨å…³ç³»
            if self.api_key:
                # æ„å»ºè¡¨ä¿¡æ¯æ‘˜è¦
                tables_summary = []
                for table in self.imported_tables:
                    summary = {
                        'table_name': table['table_name'],
                        'chinese_name': table.get('chinese_name', ''),
                        'key_fields': [col for col in table['column_names'][:10]
                                     if any(keyword in col.lower() for keyword in ['id', 'no', 'å·', 'ç¼–å·', 'code'])]
                    }
                    tables_summary.append(summary)

                prompt = f"""
è¯·åˆ†æä»¥ä¸‹é“¶è¡Œä¸šåŠ¡æ•°æ®è¡¨ä¹‹é—´çš„å…³ç³»ï¼š

è¡¨ä¿¡æ¯:
{json.dumps(tables_summary, ensure_ascii=False, indent=2)}

è¯·è¯†åˆ«è¡¨ä¹‹é—´å¯èƒ½çš„å…³è”å…³ç³»ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
  "relationships": [
    {{
      "table1": "è¡¨å1",
      "table2": "è¡¨å2",
      "relationship_type": "one_to_many|many_to_one|one_to_one",
      "common_field": "å…³è”å­—æ®µå",
      "description": "å…³ç³»æè¿°"
    }}
  ]
}}

å…³ç³»ç±»å‹è¯´æ˜ï¼š
- one_to_many: ä¸€å¯¹å¤šå…³ç³»
- many_to_one: å¤šå¯¹ä¸€å…³ç³»
- one_to_one: ä¸€å¯¹ä¸€å…³ç³»

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""

                response = self._call_llm_api(prompt, max_retries=2)
                if response:
                    try:
                        llm_result = self._parse_llm_json_response(response)
                        if llm_result and 'relationships' in llm_result:
                            return llm_result['relationships']
                    except Exception as e:
                        print(f"âš ï¸ LLMå…³ç³»åˆ†æç»“æœè§£æå¤±è´¥: {e}")

            # å¦‚æœLLMåˆ†æå¤±è´¥ï¼Œè¿”å›ç©ºå…³ç³»åˆ—è¡¨
            return []

        except Exception as e:
            print(f"âš ï¸ è¡¨å…³ç³»æ¨æ–­å¤±è´¥: {e}")
            return []

    def _get_table_description(self, table_name: str) -> str:
        """ä½¿ç”¨LLMæ™ºèƒ½ç”Ÿæˆè¡¨çš„ä¸šåŠ¡æè¿°"""
        try:
            # æŸ¥æ‰¾å¯¹åº”çš„è¡¨ä¿¡æ¯
            table_info = None
            for table in self.imported_tables:
                if table['table_name'] == table_name:
                    table_info = table
                    break

            if not table_info:
                return f'{table_name}ä¸šåŠ¡æ•°æ®è¡¨'

            # ä½¿ç”¨LLMç”Ÿæˆæè¿°
            if self.api_key:
                prompt = f"""
è¯·ä¸ºä»¥ä¸‹æ•°æ®åº“è¡¨ç”Ÿæˆç®€æ´çš„ä¸šåŠ¡æè¿°ï¼š

è¡¨å: {table_name}
ä¸­æ–‡å: {table_info.get('chinese_name', '')}
æ¥æºæ–‡ä»¶: {table_info.get('source_file', '')}
å­—æ®µæ•°é‡: {table_info.get('columns', 0)}
æ•°æ®è¡Œæ•°: {table_info.get('rows', 0)}

è¦æ±‚:
1. æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡50å­—
2. çªå‡ºè¡¨çš„ä¸»è¦ä¸šåŠ¡ç”¨é€”
3. ä½¿ç”¨ä¸“ä¸šçš„é“¶è¡Œä¸šåŠ¡æœ¯è¯­
4. åªè¿”å›æè¿°æ–‡å­—ï¼Œä¸è¦å…¶ä»–å†…å®¹

ç¤ºä¾‹: "å­˜å‚¨é“¶è¡Œå®¢æˆ·çš„å­˜æ¬¾ä½™é¢ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®¢æˆ·åŸºæœ¬ä¿¡æ¯ã€å­˜æ¬¾é‡‘é¢ã€è´¦æˆ·çŠ¶æ€ç­‰"
"""

                response = self._call_llm_api(prompt, max_retries=2)
                if response and response.strip():
                    return response.strip()

            # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›ç®€å•æè¿°
            chinese_name = table_info.get('chinese_name', '')
            if chinese_name:
                return f"{chinese_name}æ•°æ®è¡¨"
            else:
                return f"{table_name}æ•°æ®è¡¨"

        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆè¡¨æè¿°å¤±è´¥: {e}")
            return f'{table_name}ä¸šåŠ¡æ•°æ®è¡¨'

    def _identify_primary_keys(self, table_name: str, column_names: List[str]) -> List[str]:
        """æ™ºèƒ½è¯†åˆ«ä¸»é”®å­—æ®µ"""
        try:
            # ä½¿ç”¨LLMè¯†åˆ«ä¸»é”®
            if self.api_key and len(column_names) > 0:
                columns_text = ', '.join(column_names[:20])  # é™åˆ¶å­—æ®µæ•°é‡é¿å…tokenè¿‡å¤š

                prompt = f"""
è¯·ä»ä»¥ä¸‹æ•°æ®åº“è¡¨çš„å­—æ®µä¸­è¯†åˆ«å¯èƒ½çš„ä¸»é”®å­—æ®µï¼š

è¡¨å: {table_name}
å­—æ®µåˆ—è¡¨: {columns_text}

ä¸»é”®å­—æ®µé€šå¸¸å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
1. åŒ…å«IDã€ç¼–å·ã€å·ç ç­‰æ ‡è¯†ç¬¦
2. å”¯ä¸€æ ‡è¯†æ¯æ¡è®°å½•
3. é€šå¸¸ä¸ä¸ºç©º
4. å¸¸è§æ¨¡å¼ï¼š*_ID, *_NO, *ç¼–å·, *å·

è¯·è¿”å›æœ€å¯èƒ½çš„ä¸»é”®å­—æ®µåï¼Œå¦‚æœæœ‰å¤šä¸ªè¯·ç”¨é€—å·åˆ†éš”ã€‚å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„ä¸»é”®å­—æ®µï¼Œè¿”å›"æ— "ã€‚
åªè¿”å›å­—æ®µåï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""

                response = self._call_llm_api(prompt, max_retries=2)
                if response and response.strip() and response.strip() != "æ— ":
                    llm_keys = [key.strip() for key in response.strip().split(',')]
                    # éªŒè¯LLMè¿”å›çš„å­—æ®µæ˜¯å¦å­˜åœ¨äºå®é™…å­—æ®µåˆ—è¡¨ä¸­
                    valid_keys = [key for key in llm_keys if key in column_names]
                    if valid_keys:
                        return valid_keys

            # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼Œè®©æ•°æ®åº“è‡ªåŠ¨å¤„ç†
            return []

        except Exception as e:
            print(f"âš ï¸ ä¸»é”®è¯†åˆ«å¤±è´¥: {e}")
            return []

    def _categorize_table(self, table_name: str) -> str:
        """ä½¿ç”¨LLMæ™ºèƒ½å¯¹è¡¨è¿›è¡Œä¸šåŠ¡åˆ†ç±»"""
        try:
            # æŸ¥æ‰¾å¯¹åº”çš„è¡¨ä¿¡æ¯
            table_info = None
            for table in self.imported_tables:
                if table['table_name'] == table_name:
                    table_info = table
                    break

            if not table_info:
                return 'æ•°æ®è¡¨'

            # ä½¿ç”¨LLMè¿›è¡Œå¼€æ”¾å¼åˆ†ç±»
            if self.api_key:
                prompt = f"""
è¯·ä¸ºä»¥ä¸‹é“¶è¡Œä¸šåŠ¡æ•°æ®è¡¨ç”Ÿæˆä¸€ä¸ªåˆé€‚çš„ä¸šåŠ¡åˆ†ç±»ï¼š

è¡¨å: {table_name}
ä¸­æ–‡å: {table_info.get('chinese_name', '')}
æ¥æºæ–‡ä»¶: {table_info.get('source_file', '')}

è¦æ±‚:
1. åˆ†ç±»åº”è¯¥åæ˜ è¡¨çš„ä¸»è¦ä¸šåŠ¡ç”¨é€”
2. ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡è¯æ±‡ï¼ˆ2-4ä¸ªå­—ï¼‰
3. ç¬¦åˆé“¶è¡Œä¸šåŠ¡å®é™…æƒ…å†µ
4. åªè¿”å›åˆ†ç±»åç§°ï¼Œä¸è¦å…¶ä»–æ–‡å­—

ç¤ºä¾‹: "å­˜æ¬¾ä¸šåŠ¡"ã€"é£é™©ç®¡ç†"ã€"å®¢æˆ·æœåŠ¡"ç­‰
"""

                response = self._call_llm_api(prompt, max_retries=2)
                if response and response.strip():
                    category = response.strip()
                    # ç®€å•éªŒè¯ï¼šç¡®ä¿æ˜¯åˆç†é•¿åº¦çš„ä¸­æ–‡åˆ†ç±»
                    if 2 <= len(category) <= 8 and any('\u4e00' <= char <= '\u9fff' for char in category):
                        return category

            # å¦‚æœLLMå¤±è´¥ï¼ŒåŸºäºè¡¨åç”Ÿæˆç®€å•åˆ†ç±»
            if table_info.get('chinese_name'):
                return f"{table_info['chinese_name'].replace('è¡¨', '').replace('ä¿¡æ¯', '').replace('æ•°æ®', '')[:4]}ä¸šåŠ¡"
            else:
                return f"{table_name.replace('_', ' ').title()}ä¸šåŠ¡"

        except Exception as e:
            print(f"âš ï¸ è¡¨åˆ†ç±»å¤±è´¥: {e}")
            return 'ä¸šåŠ¡æ•°æ®'

    def _save_context_configuration(self, context_config: Dict[str, Any]):
        """ä¿å­˜ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶"""
        # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
        config_dir = "configs/database_contexts"
        os.makedirs(config_dir, exist_ok=True)

        # ç”Ÿæˆé…ç½®æ–‡ä»¶å
        db_name = context_config['database_info']['name']
        config_filename = f"{db_name}_context.json"
        config_path = os.path.join(config_dir, config_filename)

        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(context_config, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ ä¸Šä¸‹æ–‡é…ç½®å·²ä¿å­˜: {config_path}")

        # åŒæ—¶ä¿å­˜ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ç”¨äºå¿«é€ŸæŸ¥çœ‹
        summary_config = {
            "database_name": db_name,
            "tables": list(context_config['tables'].keys()),
            "business_terms_count": len(context_config['business_terms']),
            "field_descriptions_count": len(context_config['field_descriptions']),
            "query_rules_count": len(context_config['query_scope_rules']),
            "created_at": context_config['database_info']['created_at']
        }

        summary_path = os.path.join(config_dir, f"{db_name}_summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary_config, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ é…ç½®æ‘˜è¦å·²ä¿å­˜: {summary_path}")

    def _call_llm_api(self, prompt: str, max_retries: int = 3) -> Optional[str]:
        """è°ƒç”¨LLM APIï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        if not self.api_key:
            print("âš ï¸ æœªé…ç½®APIå¯†é’¥")
            return None

        for attempt in range(max_retries):
            try:
                print(f"ğŸ¤– LLM APIè°ƒç”¨ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")

                headers = {
                    'Authorization': f'Bearer {self.api_key}',
                    'Content-Type': 'application/json'
                }

                data = {
                    'model': 'deepseek-chat',
                    'messages': [
                        {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é“¶è¡Œä¸šåŠ¡æ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿ç”Ÿæˆä¸šåŠ¡æœ¯è¯­è¯å…¸å’Œæ•°æ®åº“ä¸Šä¸‹æ–‡é…ç½®ã€‚'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 4000,
                    'temperature': 0.1
                }

                response = requests.post(
                    'https://api.deepseek.com/chat/completions',
                    headers=headers,
                    json=data
                )

                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content'].strip()
                    print(f"âœ… LLM APIè°ƒç”¨æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                    return content
                else:
                    print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                    if attempt < max_retries - 1:
                        print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                        import time
                        time.sleep(5)

            except Exception as e:
                print(f"âŒ LLM APIè°ƒç”¨å¼‚å¸¸ (ç¬¬ {attempt + 1} æ¬¡): {e}")
                if attempt < max_retries - 1:
                    print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                    import time
                    time.sleep(5)

        print(f"âŒ LLM APIè°ƒç”¨æœ€ç»ˆå¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
        return None

    def _clean_llm_response(self, response: str) -> str:
        """æ¸…ç†LLMå“åº”ï¼Œæå–JSONéƒ¨åˆ†"""
        if not response:
            return ""

        response = response.strip()

        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        if response.startswith('```json'):
            response = response[7:]
        if response.startswith('```'):
            response = response[3:]
        if response.endswith('```'):
            response = response[:-3]

        response = response.strip()

        # æŸ¥æ‰¾JSONå¼€å§‹å’Œç»“æŸä½ç½®
        json_start = response.find('{')
        if json_start == -1:
            return response

        brace_count = 0
        json_end = -1

        for i in range(json_start, len(response)):
            if response[i] == '{':
                brace_count += 1
            elif response[i] == '}':
                brace_count -= 1
                if brace_count == 0:
                    json_end = i + 1
                    break

        if json_end == -1:
            return response[json_start:]

        return response[json_start:json_end]

    def _parse_llm_json_response(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMçš„JSONå“åº”"""
        try:
            # æ¸…ç†å“åº”å†…å®¹
            cleaned_response = self._clean_llm_response(response)

            # å°è¯•è§£æJSON
            parsed_result = json.loads(cleaned_response)
            return parsed_result

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"âŒ å“åº”è§£æå¤±è´¥: {e}")
            return None

    def _generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        return {
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'database_path': self.output_db_path,
            'workflow_steps': {
                'step1_business_data_imported': len(self.imported_tables),
                'step2_dictionaries_analyzed': len(self.dictionary_files),
                'step3_business_terms_generated': len(self.business_terms),
                'step4_context_configuration_created': True
            },
            'tables': self.imported_tables,
            'business_terms_count': len(self.business_terms),
            'field_descriptions_count': len(self.field_descriptions),
            'query_rules_count': len(self.query_scope_rules),
            'total_rows': sum(table['rows'] for table in self.imported_tables),
            'total_columns': sum(table['columns'] for table in self.imported_tables),
            'context_files_generated': True
        }

# CLIæ¥å£å‡½æ•°
def generate_database_with_context(data_dir: str, output_db: Optional[str] = None,
                                 api_key: Optional[str] = None) -> Dict[str, Any]:
    """CLIæ¥å£å‡½æ•°ï¼šç”Ÿæˆæ•°æ®åº“å’Œä¸Šä¸‹æ–‡é…ç½®"""
    if not output_db:
        timestamp = int(datetime.now().timestamp())
        output_db = f"databases/imported/context_generated_db_{timestamp}.db"

    # ç¡®ä¿è¾“å‡ºåˆ°databases/importedç›®å½•
    if not output_db.startswith('databases/'):
        output_db = f"databases/imported/{os.path.basename(output_db)}"

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_db), exist_ok=True)

    generator = DictionaryContextGenerator(output_db, api_key)
    return generator.generate_database_with_context(data_dir)

def main():
    """ä¸»å‡½æ•° - å¯ç›´æ¥æ‰§è¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description='æ•°æ®å­—å…¸é©±åŠ¨çš„ä¸Šä¸‹æ–‡æ–‡ä»¶ç”Ÿæˆå™¨')
    parser.add_argument('data_dir', help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--api-key', help='LLM APIå¯†é’¥')

    args = parser.parse_args()

    try:
        # æ‰§è¡Œæ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆ
        report = generate_database_with_context(
            args.data_dir,
            args.output,
            args.api_key
        )

        # ä¿å­˜æŠ¥å‘Š
        timestamp = int(datetime.now().timestamp())
        report_file = f"context_generation_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“‹ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š æ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆç»“æœ:")
        print(f"   æ•°æ®åº“æ–‡ä»¶: {report['database_path']}")
        print(f"   æ€»è¡¨æ•°: {len(report['tables'])}")
        print(f"   æ€»è¡Œæ•°: {report['total_rows']:,}")
        print(f"   ä¸šåŠ¡æœ¯è¯­: {report['business_terms_count']} ä¸ª")
        print(f"   å­—æ®µæè¿°: {report['field_descriptions_count']} ä¸ª")
        print(f"   æŸ¥è¯¢è§„åˆ™: {report['query_rules_count']} ä¸ª")

        for table in report['tables']:
            print(f"   ğŸ“‹ {table['table_name']}: {table['rows']:,}è¡Œ ({table['chinese_name']})")

        print(f"\nğŸ‰ æ•°æ®å­—å…¸é©±åŠ¨çš„æ•°æ®åº“å’Œä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ’¡ ä¸Šä¸‹æ–‡é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ° configs/database_contexts/ ç›®å½•")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
