#!/usr/bin/env python3
"""
DataProxy Flask API Backend
åŸºäºStreamlitæ ¸å¿ƒé€»è¾‘çš„ç®€åŒ–APIå®ç°
"""

import os
import sys
import json
import time
import asyncio
import tempfile
import shutil
import signal
import atexit
import numpy as np
import pandas as pd
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
from werkzeug.utils import secure_filename

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(os.path.join(project_root, '.env'))

# ğŸ”¥ å¯¼å…¥ç®€åŒ–åçš„æ ¸å¿ƒæ¨¡å—
try:
    from core_modules.config import get_unified_config, reset_unified_config
    from core_modules.utils import FileConverter

    # å¯¼å…¥æ ¸å¿ƒæ¨¡å—
    try:
        from core_modules.visualization import get_chart_system
        CHART_SYSTEM_AVAILABLE = True
    except ImportError:
        CHART_SYSTEM_AVAILABLE = False

    try:
        from core_modules.agent.consolidated_tool_registry import (
            get_tool_registry,
            create_dataproxy_tools,
            get_system_health
        )
        from core_modules.agent.simplified_dataproxy_tool import SimplifiedDataProxyTool
        UNIFIED_TOOLS_AVAILABLE = True
    except ImportError as e:
        UNIFIED_TOOLS_AVAILABLE = False
        UNIFIED_TOOLS_ERROR = str(e)

    try:
        from core_modules.visualization.enhanced_visualization_langchain_tool import EnhancedVisualizationTool
        ENHANCED_VIZ_AVAILABLE = True
    except ImportError as e:
        ENHANCED_VIZ_AVAILABLE = False
        ENHANCED_VIZ_ERROR = str(e)

    try:
        from core_modules.analytics import smart_stats_analyzer
        SMART_STATS_AVAILABLE = True
    except ImportError as e:
        SMART_STATS_AVAILABLE = False

    try:
        from core_modules.config.metadata_aware_unified_config import MetadataAwareUnifiedConfig
        from core_modules.config.metadata_aware_context_generator import MetadataAwareContextGenerator
        from core_modules.nl2sql.metadata_aware_nl2sql_enhancer import MetadataAwareNL2SQLEnhancer
        METADATA_AWARE_AVAILABLE = True
    except ImportError as e:
        METADATA_AWARE_AVAILABLE = False
        METADATA_AWARE_ERROR = str(e)

    try:
        from core_modules.data_import import IntelligentDataImporter
        INTELLIGENT_IMPORT_AVAILABLE = True
    except ImportError as e:
        INTELLIGENT_IMPORT_AVAILABLE = False
        INTELLIGENT_IMPORT_ERROR = str(e)

    try:
        from core_modules.analytics import table_statistics_analyzer, simple_insights_generator
        NEW_INSIGHTS_AVAILABLE = True
    except ImportError as e:
        NEW_INSIGHTS_AVAILABLE = False

    try:
        from core_modules.analytics import enhanced_insights_generator
        ENHANCED_INSIGHTS_AVAILABLE = True
    except ImportError as e:
        ENHANCED_INSIGHTS_AVAILABLE = False

    # æ£€æŸ¥DataProxyå·¥å…·æ˜¯å¦å¯ç”¨
    DATAPROXY_TOOL_AVAILABLE = False
    dataproxy_tool = None

    try:
        from core_modules.agent.dataproxy_tool import DataProxyTool
        dataproxy_tool = DataProxyTool()
        DATAPROXY_TOOL_AVAILABLE = True
        print("âœ… DataProxyå·¥å…·: å·²åŠ è½½")
    except ImportError:
        print("â„¹ï¸ DataProxyå·¥å…·: ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")

except ImportError as e:
    print(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# æ•°æ®æ¸…ç†å‡½æ•°
def clean_data_for_json(data):
    """æ¸…ç†æ•°æ®ä»¥ä¾¿JSONåºåˆ—åŒ–"""
    if isinstance(data, dict):
        return {k: clean_data_for_json(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [clean_data_for_json(item) for item in data]
    elif isinstance(data, pd.DataFrame):
        return data.to_dict('records')
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif isinstance(data, (np.integer, np.floating)):
        return data.item()
    elif isinstance(data, np.bool_):
        return bool(data)
    elif pd.isna(data):
        return None
    else:
        return data

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)  # å¯ç”¨CORSæ”¯æŒ

# æ³¨å†Œæ‰€æœ‰APIè“å›¾
try:
    # ç³»ç»Ÿç®¡ç†API
    from flask_backend.api.system_endpoints import create_system_blueprint
    system_bp = create_system_blueprint()
    app.register_blueprint(system_bp)
    print("âœ… ç³»ç»Ÿç®¡ç†API: å·²æ³¨å†Œ")

    # æ•°æ®åº“ç®¡ç†API
    from flask_backend.api.database_endpoints import create_database_blueprint
    database_bp = create_database_blueprint()
    app.register_blueprint(database_bp)
    print("âœ… æ•°æ®åº“ç®¡ç†API: å·²æ³¨å†Œ")

    # æ–‡ä»¶ç®¡ç†API
    from flask_backend.api.file_endpoints import create_file_blueprint
    file_bp = create_file_blueprint()
    app.register_blueprint(file_bp)
    print("âœ… æ–‡ä»¶ç®¡ç†API: å·²æ³¨å†Œ")

    # ä¸Šä¸‹æ–‡ç®¡ç†API
    from flask_backend.api.context_endpoints import create_context_blueprint
    context_bp = create_context_blueprint()
    app.register_blueprint(context_bp)
    print("âœ… ä¸Šä¸‹æ–‡ç®¡ç†API: å·²æ³¨å†Œ")

    # å¯è§†åŒ–API
    from flask_backend.api.visualization_endpoints import create_visualization_blueprint
    viz_bp = create_visualization_blueprint()
    app.register_blueprint(viz_bp)
    print("âœ… å¯è§†åŒ–API: å·²æ³¨å†Œ")

    # é…ç½®ç®¡ç†API
    from flask_backend.api.config_endpoints import create_config_blueprint
    config_bp = create_config_blueprint()
    app.register_blueprint(config_bp)
    print("âœ… é…ç½®ç®¡ç†API: å·²æ³¨å†Œ")

    # æŸ¥è¯¢APIï¼ˆåŸæœ‰çš„ï¼‰
    from flask_backend.api.query_endpoints import create_query_blueprint
    # æ€»æ˜¯æ³¨å†ŒæŸ¥è¯¢APIï¼Œå³ä½¿å·¥å…·ä¸å¯ç”¨ä¹Ÿæä¾›åŸºç¡€åŠŸèƒ½
    query_bp = create_query_blueprint(dataproxy_tool if DATAPROXY_TOOL_AVAILABLE else None)
    app.register_blueprint(query_bp)
    print("âœ… æŸ¥è¯¢API: å·²æ³¨å†Œ")

except ImportError as e:
    print(f"â„¹ï¸ APIè“å›¾å¯¼å…¥: {e}")
    print("â„¹ï¸ ä½¿ç”¨åŸºç¡€ç«¯ç‚¹")

# å…¨å±€çŠ¶æ€ç®¡ç†ï¼ˆæ¨¡ä»¿Streamlitçš„session_stateï¼‰
class GlobalState:
    def __init__(self):
        self.initialized = False
        self.unified_config = None
        self.agent = None
        self.available_databases = {}
        self.current_database = None
        self.simple_charts = []
        self.chart_system = None
        self.context_manager = None
        self.file_manager = None
        self.file_converter = None

        # ğŸ”¥ æ–°å¢ï¼šå…ƒæ•°æ®æ„ŸçŸ¥ç»„ä»¶
        self.metadata_aware_config = None
        self.metadata_enhancer = None
        self.metadata_enhanced = False

    def initialize(self):
        """åˆå§‹åŒ–å…¨å±€çŠ¶æ€ï¼ˆæ¨¡ä»¿Streamlitçš„åˆå§‹åŒ–é€»è¾‘ï¼‰"""
        if self.initialized:
            return True

        try:
            print("[INFO] åˆå§‹åŒ–DataProxyå…¨å±€çŠ¶æ€ï¼ˆå…ƒæ•°æ®æ„ŸçŸ¥ç‰ˆæœ¬ï¼‰...")

            # ğŸ”¥ ä¼˜å…ˆå°è¯•ä½¿ç”¨å…ƒæ•°æ®æ„ŸçŸ¥é…ç½®
            if METADATA_AWARE_AVAILABLE:
                try:
                    self.metadata_aware_config = MetadataAwareUnifiedConfig()
                    self.unified_config = self.metadata_aware_config
                    self.metadata_enhanced = True
                    print("âœ… ä½¿ç”¨å…ƒæ•°æ®æ„ŸçŸ¥é…ç½®ç®¡ç†å™¨")
                except Exception as e:
                    print(f"âš ï¸ å…ƒæ•°æ®æ„ŸçŸ¥é…ç½®åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼: {e}")
                    self.unified_config = get_unified_config()
                    self.metadata_enhanced = False
            else:
                # é™çº§åˆ°ä¼ ç»Ÿé…ç½®
                self.unified_config = get_unified_config()
                self.metadata_enhanced = False
                print("ğŸ“‹ ä½¿ç”¨ä¼ ç»Ÿé…ç½®ç®¡ç†å™¨")
            
            # è·å–å¯ç”¨æ•°æ®åº“
            self.available_databases = self.unified_config.get_available_databases()
            print(f"[INFO] å‘ç° {len(self.available_databases)} ä¸ªå¯ç”¨æ•°æ®åº“")
            
            # ğŸ”¥ ä¿®å¤ï¼šåªé€‰æ‹©æ–‡ä»¶å­˜åœ¨çš„æ•°æ®åº“
            available_dbs = [
                db_path for db_path, db_info in self.available_databases.items()
                if db_info.get('file_exists', True) and db_info.get('status') == 'available'
            ]

            if available_dbs:
                first_db_path = available_dbs[0]
                print(f"[INFO] è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ•°æ®åº“: {first_db_path}")

                success = self.unified_config.switch_database(first_db_path)
                if success:
                    self.current_database = first_db_path
                    print(f"[INFO] æ•°æ®åº“åˆ‡æ¢æˆåŠŸ: {first_db_path}")

                    # ğŸ”¥ åˆå§‹åŒ–å…ƒæ•°æ®å¢å¼ºå™¨
                    self._initialize_metadata_enhancer()
                else:
                    print(f"[ERROR] æ•°æ®åº“åˆ‡æ¢å¤±è´¥: {first_db_path}")
            else:
                print(f"[WARNING] æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ•°æ®åº“æ–‡ä»¶")
            
            # ğŸ”¥ åˆå§‹åŒ–ç®€åŒ–çš„DataProxyå·¥å…·
            if UNIFIED_TOOLS_AVAILABLE:
                self.dataproxy_tool = SimplifiedDataProxyTool()
                print("âœ… ç®€åŒ–DataProxyå·¥å…·åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.dataproxy_tool = None
                print("âŒ ç»Ÿä¸€å·¥å…·ç³»ç»Ÿä¸å¯ç”¨")
            
            # åˆå§‹åŒ–å…¶ä»–ç»„ä»¶ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            try:
                self.context_manager = self._get_simple_context_manager()
                self.file_manager = self._get_simple_file_manager()
                self.file_converter = self._get_simple_file_converter()
                self.chart_system = self._get_simple_chart_system()
                print("âœ… ç®€åŒ–ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARNING] ç»„ä»¶åˆå§‹åŒ–éƒ¨åˆ†å¤±è´¥: {e}")
                # è®¾ç½®é»˜è®¤å€¼
                self.context_manager = None
                self.file_manager = None
                self.file_converter = None
                self.chart_system = None
            
            self.initialized = True
            print("[INFO] å…¨å±€çŠ¶æ€åˆå§‹åŒ–å®Œæˆ")
            return True

        except Exception as e:
            print(f"[ERROR] å…¨å±€çŠ¶æ€åˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
            return False

    def _get_simple_context_manager(self):
        """è·å–ç®€åŒ–çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        class SimpleContextManager:
            def get_context(self, database_path):
                return {"database_path": database_path, "tables": {}}

            def update_context(self, database_path, context):
                return True

            def list_contexts(self):
                return []

        return SimpleContextManager()

    def _get_simple_file_manager(self):
        """è·å–ç®€åŒ–çš„æ–‡ä»¶ç®¡ç†å™¨"""
        class SimpleFileManager:
            def process_file(self, file_path):
                return {"status": "processed", "file_path": file_path}

        return SimpleFileManager()

    def _get_simple_file_converter(self):
        """è·å–ç®€åŒ–çš„æ–‡ä»¶è½¬æ¢å™¨"""
        class SimpleFileConverter:
            def convert_to_database(self, file_path):
                return {"status": "converted", "database_path": file_path.replace('.xlsx', '.db')}

        return SimpleFileConverter()

    def _get_simple_chart_system(self):
        """è·å–ç®€åŒ–çš„å›¾è¡¨ç³»ç»Ÿ"""
        try:
            from core_modules.visualization import get_chart_system
            return get_chart_system()
        except ImportError:
            class SimpleChartSystem:
                def create_chart(self, data, chart_type, **kwargs):
                    return {"status": "created", "chart_type": chart_type}

            return SimpleChartSystem()

    def _initialize_metadata_enhancer(self):
        """åˆå§‹åŒ–å…ƒæ•°æ®å¢å¼ºå™¨"""
        if self.metadata_enhanced and METADATA_AWARE_AVAILABLE:
            try:
                self.metadata_enhancer = MetadataAwareNL2SQLEnhancer(self.metadata_aware_config)
                print("âœ… å…ƒæ•°æ®æ„ŸçŸ¥NL2SQLå¢å¼ºå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ å…ƒæ•°æ®å¢å¼ºå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.metadata_enhancer = None

    def process_query_enhanced(self, query: str) -> dict:
        """å¢å¼ºçš„æŸ¥è¯¢å¤„ç†æ–¹æ³•"""
        try:
            # ğŸ”¥ å¦‚æœæœ‰å…ƒæ•°æ®å¢å¼ºå™¨ï¼Œå…ˆè¿›è¡ŒæŸ¥è¯¢å¢å¼º
            query_enhancement = {}
            if self.metadata_enhancer:
                query_enhancement = self.metadata_enhancer.enhance_query(query)
                print(f"[DEBUG] æŸ¥è¯¢å¢å¼ºå®Œæˆ: {len(query_enhancement.get('field_mappings', {}))} ä¸ªå­—æ®µæ˜ å°„")

            # ä½¿ç”¨DataProxyå·¥å…·å¤„ç†æŸ¥è¯¢
            if not hasattr(self, 'dataproxy_tool') or not self.dataproxy_tool:
                return {"success": False, "error": "DataProxyå·¥å…·ä¸å¯ç”¨"}

            # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨æ­£ç¡®çš„å‚æ•°ï¼‰
            result = self.dataproxy_tool._run(query)

            # ğŸ”¥ åœ¨å“åº”ä¸­æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
            if query_enhancement.get('metadata_enhanced'):
                if 'metadata_info' not in result:
                    result['metadata_info'] = {}

                result['metadata_info'].update({
                    'field_mappings': query_enhancement.get('field_mappings', {}),
                    'business_rules': query_enhancement.get('business_rules', {}),
                    'suggestions': query_enhancement.get('suggestions', []),
                    'enhanced_query': query_enhancement.get('enhanced_query', query)
                })

            return result

        except Exception as e:
            print(f"[ERROR] å¢å¼ºæŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

# å…¨å±€çŠ¶æ€å®ä¾‹
global_state = GlobalState()

# Flask Callback Handlerï¼ˆæ¨¡ä»¿Streamlitçš„SimpleCallbackHandlerï¼‰
class FlaskCallbackHandler:
    def __init__(self):
        self.tool_calls = []
        self.current_tool = None
        self.run_inline = True
        self.ignore_chain = False
        self.ignore_agent = False
        self.ignore_llm = False
        self.ignore_retriever = False
        self.ignore_chat_model = False
        self.raise_error = False

        # å¯è§†åŒ–æ•°æ®æ”¶é›†ï¼ˆæ¨¡ä»¿Streamlitï¼‰
        self.charts_to_add = []
        self.pending_viz_tasks = []
        self.session_start_time = time.time()

        # ğŸ”¥ æ–°å¢ï¼šæŸ¥è¯¢åˆ†è§£æ§åˆ¶å‚æ•°
        self.enable_decomposition = True  # é»˜è®¤å¯ç”¨åˆ†è§£

    def on_tool_start(self, serialized, input_str, **kwargs):
        self.current_tool = serialized.get('name', 'unknown') if serialized else 'unknown'

        # ğŸ”¥ æ–°å¢ï¼šå¦‚æœæ˜¯DataProxyå·¥å…·ï¼Œæ³¨å…¥åˆ†è§£æ§åˆ¶å‚æ•°
        if self.current_tool == 'dataproxy_analysis':
            print(f"[DEBUG] FlaskCallbackHandler: æ‹¦æˆªDataProxyå·¥å…·è°ƒç”¨ï¼Œæ³¨å…¥åˆ†è§£æ§åˆ¶å‚æ•°")
            print(f"[DEBUG] FlaskCallbackHandler: enable_decomposition = {self.enable_decomposition}")

            # ä¿®æ”¹å·¥å…·è¾“å…¥ä»¥åŒ…å«åˆ†è§£æ§åˆ¶å‚æ•°
            try:
                import json
                if isinstance(input_str, str):
                    # å°è¯•è§£æJSONè¾“å…¥
                    try:
                        tool_input = json.loads(input_str)
                        tool_input['enable_decomposition'] = self.enable_decomposition
                        modified_input = json.dumps(tool_input)
                        print(f"[DEBUG] FlaskCallbackHandler: å·²æ³¨å…¥åˆ†è§£æ§åˆ¶å‚æ•°åˆ°å·¥å…·è¾“å…¥")
                        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥ä¿®æ”¹input_strï¼Œä½†å¯ä»¥è®°å½•è¿™ä¸ªä¿¡æ¯
                    except json.JSONDecodeError:
                        print(f"[DEBUG] FlaskCallbackHandler: å·¥å…·è¾“å…¥ä¸æ˜¯JSONæ ¼å¼ï¼Œæ— æ³•æ³¨å…¥å‚æ•°")
            except Exception as e:
                print(f"[DEBUG] FlaskCallbackHandler: æ³¨å…¥åˆ†è§£æ§åˆ¶å‚æ•°å¤±è´¥: {e}")

    def on_tool_end(self, output, **kwargs):
        tool_call_data = {
            "tool_name": self.current_tool or 'unknown',
            "input_args": {},
            "output": output,
            "success": True
        }
        self.tool_calls.append(tool_call_data)
        
        # æ£€æŸ¥å·¥å…·è¾“å‡ºæ˜¯å¦åŒ…å«å¯è§†åŒ–æ•°æ®
        self._check_for_visualization_data(tool_call_data)

    def on_tool_error(self, error, **kwargs):
        self.tool_calls.append({
            "tool_name": self.current_tool or 'unknown',
            "input_args": {},
            "output": None,
            "success": False,
            "error": str(error)
        })
    
    def _check_for_visualization_data(self, tool_call_data):
        """æ£€æŸ¥å·¥å…·è°ƒç”¨ç»“æœä¸­æ˜¯å¦åŒ…å«å¯è§†åŒ–æ•°æ®ï¼ˆæ¨¡ä»¿Streamlité€»è¾‘ï¼‰"""
        try:
            output = tool_call_data.get('output')
            if not output:
                return
            
            # å¦‚æœoutputæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
            if isinstance(output, str):
                try:
                    output = json.loads(output)
                except:
                    return
            
            if not isinstance(output, dict):
                return
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯è§†åŒ–ç›¸å…³çš„æ•°æ®
            has_viz_data = (
                'visualizations' in output or
                'data_tables' in output or
                'data' in output or
                (output.get('success') and len(output.get('data', [])) > 0)
            )
            
            if has_viz_data:
                print(f"[DEBUG] Flask Callback: å‘ç°å¯è§†åŒ–æ•°æ®åœ¨å·¥å…· {tool_call_data['tool_name']}")
                
                # åˆ›å»ºå¯è§†åŒ–ä»»åŠ¡
                viz_task = {
                    'tool_result': output,
                    'original_query': getattr(self, 'current_query', 'æ•°æ®åˆ†æ'),
                    'timestamp': time.time(),
                    'status': 'pending',
                    'tool_name': tool_call_data['tool_name']
                }
                
                self.pending_viz_tasks.append(viz_task)
                print(f"[DEBUG] Flask Callback: æ·»åŠ å¯è§†åŒ–ä»»åŠ¡ï¼Œå½“å‰ä»»åŠ¡æ•°: {len(self.pending_viz_tasks)}")
                
        except Exception as e:
            print(f"[DEBUG] Flask Callback: æ£€æŸ¥å¯è§†åŒ–æ•°æ®æ—¶å‡ºé”™ - {e}")
    
    def get_pending_viz_tasks(self):
        """è·å–å¾…å¤„ç†çš„å¯è§†åŒ–ä»»åŠ¡"""
        return self.pending_viz_tasks
    
    def set_current_query(self, query):
        """è®¾ç½®å½“å‰æŸ¥è¯¢"""
        self.current_query = query

    # æ·»åŠ æ‰€æœ‰ç¼ºå¤±çš„callbackæ–¹æ³•
    def on_llm_start(self, serialized, prompts, **kwargs):
        pass

    def on_llm_new_token(self, token, **kwargs):
        pass

    def on_llm_end(self, response, **kwargs):
        pass

    def on_llm_error(self, error, **kwargs):
        pass

    def on_chain_start(self, serialized, inputs, **kwargs):
        pass

    def on_chain_end(self, outputs, **kwargs):
        pass

    def on_chain_error(self, error, **kwargs):
        pass

    def on_agent_action(self, action, **kwargs):
        pass

    def on_agent_finish(self, finish, **kwargs):
        pass

    def on_chat_model_start(self, serialized, messages, **kwargs):
        pass

async def process_pending_enhanced_visualizations_flask(pending_tasks):
    """å¤„ç†å¾…å¤„ç†çš„å¢å¼ºå¯è§†åŒ–ä»»åŠ¡ - Flaskç‰ˆæœ¬ï¼ˆç›´æ¥ä½¿ç”¨Streamlité€»è¾‘ï¼‰"""
    generated_charts = []
    
    if not pending_tasks:
        print("[DEBUG] Flaskå¯è§†åŒ–ï¼šæ²¡æœ‰å¾…å¤„ç†çš„ä»»åŠ¡")
        return generated_charts
    
    if not ENHANCED_VIZ_AVAILABLE:
        print("[DEBUG] Flaskå¯è§†åŒ–ï¼šå¢å¼ºå¯è§†åŒ–æ¨¡å—ä¸å¯ç”¨")
        return generated_charts
    
    try:
        # å¯¼å…¥å¢å¼ºå¯è§†åŒ–æ¨¡å—
        from core_modules.visualization.enhanced_visualization_langchain_tool import EnhancedVisualizationTool
        viz_tool = EnhancedVisualizationTool()
        
        for task in pending_tasks:
            if task.get('status') != 'pending':
                continue
                
            print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šå¤„ç†ä»»åŠ¡ - {task['original_query']}")
            
            # æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
            task['status'] = 'processing'
            
            # æå–åŸå§‹æŸ¥è¯¢å­—ç¬¦ä¸²
            original_query = task.get('original_query', 'æ•°æ®åˆ†æ')
            if not isinstance(original_query, str):
                original_query = str(original_query)
            
            # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®æå–æ•°æ®è¡¨
            tool_result = task['tool_result']
            print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼štool_resultç±»å‹: {type(tool_result)}")
            print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼štool_resulté”®: {list(tool_result.keys()) if isinstance(tool_result, dict) else 'not dict'}")

            # å°è¯•å¤šç§æ–¹å¼æå–æ•°æ®è¡¨
            all_data_tables = {}

            # æ–¹å¼1ï¼šç›´æ¥ä»tool_resultä¸­æå–data_tables
            if isinstance(tool_result, dict) and 'data_tables' in tool_result:
                print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šå‘ç°ç›´æ¥çš„data_tables")
                data_tables = tool_result['data_tables']
                if isinstance(data_tables, dict):
                    for table_name, table_data in data_tables.items():
                        if isinstance(table_data, list) and table_data:
                            all_data_tables[table_name] = table_data
                            print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šâœ… æå–è¡¨ {table_name}ï¼Œæ•°æ®é‡: {len(table_data)}")

            # æ–¹å¼2ï¼šä½¿ç”¨å¯è§†åŒ–å·¥å…·çš„æå–æ–¹æ³•ä½œä¸ºå¤‡ç”¨
            if not all_data_tables:
                print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šå°è¯•ä½¿ç”¨å¯è§†åŒ–å·¥å…·æå–æ–¹æ³•")
                all_data_tables = viz_tool._extract_all_visualization_data_from_dataproxy(tool_result)

            # æ–¹å¼3ï¼šå¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰visualization_dataç»“æ„
            if not all_data_tables and isinstance(tool_result, dict):
                if 'visualization_data' in tool_result:
                    viz_data = tool_result['visualization_data']
                    if isinstance(viz_data, dict) and 'data_tables' in viz_data:
                        print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šå‘ç°visualization_data.data_tables")
                        data_tables = viz_data['data_tables']
                        if isinstance(data_tables, dict):
                            for table_name, table_data in data_tables.items():
                                if isinstance(table_data, list) and table_data:
                                    all_data_tables[table_name] = table_data
                                    print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šâœ… ä»visualization_dataæå–è¡¨ {table_name}ï¼Œæ•°æ®é‡: {len(table_data)}")

            # æ–¹å¼4ï¼šğŸ”§ æ–°å¢ï¼šç›´æ¥ä»dataå­—æ®µåˆ›å»ºæ•°æ®è¡¨ï¼ˆé’ˆå¯¹NL2SQLç»“æœï¼‰
            if not all_data_tables and isinstance(tool_result, dict) and 'data' in tool_result:
                data = tool_result['data']
                if isinstance(data, list) and data:
                    print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šå‘ç°ç›´æ¥çš„dataå­—æ®µï¼Œæ•°æ®é‡: {len(data)}")
                    # ä½¿ç”¨æŸ¥è¯¢å†…å®¹ä½œä¸ºè¡¨å
                    table_name = task.get('original_query', 'æŸ¥è¯¢ç»“æœ')
                    if len(table_name) > 20:
                        table_name = table_name[:20] + "..."
                    all_data_tables[table_name] = data
                    print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šâœ… ä»dataå­—æ®µåˆ›å»ºè¡¨ {table_name}ï¼Œæ•°æ®é‡: {len(data)}")

            if not all_data_tables:
                print(f"[WARN] Flaskå¯è§†åŒ–ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®è¡¨")
                print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼štool_resultå†…å®¹é¢„è§ˆ: {str(tool_result)[:500]}...")
                task['status'] = 'failed'
                continue
            
            print(f"[INFO] Flaskå¯è§†åŒ–ï¼šæ‰¾åˆ° {len(all_data_tables)} ä¸ªæ•°æ®è¡¨ï¼Œå°†ä¸ºæ¯ä¸ªè¡¨ç”Ÿæˆå›¾è¡¨")
            
            # ä¸ºæ¯ä¸ªæ•°æ®è¡¨ç”Ÿæˆç‹¬ç«‹çš„å›¾è¡¨
            for table_name, table_data in all_data_tables.items():
                try:
                    print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šä¸ºè¡¨ '{table_name}' ç”Ÿæˆå›¾è¡¨ï¼Œæ•°æ®é‡: {len(table_data)}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šæå–ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼Œé¿å…ç³»ç»Ÿå†…éƒ¨æè¿°
                    # ä»original_queryä¸­æå–çœŸæ­£çš„ç”¨æˆ·æŸ¥è¯¢
                    user_query = str(original_query)

                    # å¦‚æœåŒ…å«ç³»ç»Ÿæè¿°ï¼Œæå–ç”¨æˆ·æŸ¥è¯¢éƒ¨åˆ†
                    if "è¯·ä½¿ç”¨DataProxyå·¥å…·åˆ†æä»¥ä¸‹æŸ¥è¯¢" in user_query:
                        # æå–å†’å·åçš„ç”¨æˆ·æŸ¥è¯¢éƒ¨åˆ†
                        parts = user_query.split("ï¼š")
                        if len(parts) > 1:
                            user_query = parts[-1].strip()

                    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦å¹¶é™åˆ¶é•¿åº¦
                    safe_query = user_query.replace("'", "").replace('"', '').replace('{', '').replace('}', '')
                    if len(safe_query) > 30:
                        safe_query = "æ•°æ®åˆ†æ"

                    table_viz_query = f"åŸºäº{table_name}æ•°æ®è¡¨çš„åˆ†æç»“æœï¼Œä¸º{safe_query}æŸ¥è¯¢ç”Ÿæˆä¸“ä¸šçš„å¯è§†åŒ–å›¾è¡¨"
                    
                    # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®ä¼ é€’æ•°æ®ç»™å¯è§†åŒ–å·¥å…·
                    print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šå‡†å¤‡ä¼ é€’æ•°æ®ç»™å¯è§†åŒ–å·¥å…·ï¼Œæ•°æ®ç±»å‹: {type(table_data)}")
                    print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šæ•°æ®å†…å®¹é¢„è§ˆ: {table_data[:2] if isinstance(table_data, list) and table_data else 'empty'}")

                    # æ„é€ æ­£ç¡®çš„æ•°æ®æ ¼å¼
                    viz_data = {
                        'data_tables': {
                            table_name: table_data
                        },
                        'query_result': {
                            'data_tables': {
                                table_name: table_data
                            }
                        }
                    }

                    # ğŸ”¥ ä¿®å¤ï¼šè·å–å¹¶ä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯
                    viz_config = {
                        'height': 500,
                        'color_scheme': 'business',
                        'theme': 'professional'
                    }

                    # å°è¯•è·å–å½“å‰çš„ç»Ÿä¸€é…ç½®ä¸Šä¸‹æ–‡
                    try:
                        from core_modules.config import get_unified_config
                        unified_config = get_unified_config()
                        if unified_config and unified_config.is_valid():
                            context = unified_config.create_context(original_query)
                            viz_config['context'] = context
                            viz_config['original_user_query'] = original_query
                            print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šä¸ºè¡¨ '{table_name}' ä¼ é€’ä¸Šä¸‹æ–‡ï¼Œä¸šåŠ¡æœ¯è¯­æ•°é‡: {len(context.business_terms)}")
                        else:
                            print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šè¡¨ '{table_name}' æ— æ³•è·å–æœ‰æ•ˆä¸Šä¸‹æ–‡")
                    except Exception as ctx_error:
                        print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šè·å–ä¸Šä¸‹æ–‡å¤±è´¥: {ctx_error}")

                    # ä½¿ç”¨åŒæ­¥æ–¹å¼è°ƒç”¨å¯è§†åŒ–å·¥å…·
                    viz_result = viz_tool._run(
                        data=viz_data,
                        user_query=table_viz_query,
                        config=viz_config
                    )
                    
                    # å¤„ç†å¯è§†åŒ–ç»“æœ
                    if viz_result.get('success'):
                        print(f"[INFO] Flaskå¯è§†åŒ–ï¼šè¡¨ '{table_name}' å›¾è¡¨ç”ŸæˆæˆåŠŸ")
                        
                        # æå–å›¾è¡¨å†…å®¹
                        figure_html = viz_result.get('figure_html')
                        figure_json = viz_result.get('figure_json')
                        visualizations = viz_result.get('visualizations', [])
                        
                        # ä»visualizationsä¸­æå–HTMLå’ŒJSONï¼ˆå¦‚æœä¸»å­—æ®µä¸ºç©ºï¼‰
                        if not figure_html and visualizations:
                            for viz in visualizations:
                                if isinstance(viz, dict):
                                    for field in ['figure_html', 'html', 'chart_html', 'content']:
                                        if viz.get(field):
                                            figure_html = viz[field]
                                            break
                                    if figure_html:
                                        break
                        
                        # å¦‚æœæœ‰ä»»ä½•å¯ç”¨çš„å›¾è¡¨å†…å®¹
                        if figure_html or figure_json:
                            chart_info = {
                                'figure_html': figure_html,
                                'figure_json': figure_json,
                                'title': f"{table_name} - {original_query}",
                                'chart_type': 'enhanced_multi',
                                'data_count': len(table_data),
                                'chart_id': f"flask_chart_{table_name}_{int(task['timestamp'])}",
                                'table_name': table_name,
                                'quality_assessment': viz_result.get('quality_assessment', {}),
                                'generated_code': viz_result.get('generated_code', ''),
                                'execution_time': viz_result.get('execution_time', 0),
                                'source': 'flask_enhanced_visualization'
                            }
                            
                            generated_charts.append(chart_info)
                            print(f"[INFO] Flaskå¯è§†åŒ–ï¼šè¡¨ '{table_name}' å·²æ·»åŠ åˆ°å›¾è¡¨åˆ—è¡¨")
                        else:
                            print(f"[WARN] Flaskå¯è§†åŒ–ï¼šè¡¨ '{table_name}' ç”ŸæˆæˆåŠŸä½†æ²¡æœ‰HTMLæˆ–JSONå†…å®¹")
                    else:
                        print(f"[WARN] Flaskå¯è§†åŒ–ï¼šè¡¨ '{table_name}' ç”Ÿæˆå¤±è´¥ - {viz_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    print(f"[ERROR] Flaskå¯è§†åŒ–ï¼šè¡¨ '{table_name}' å¤„ç†å¤±è´¥ - {e}")
                    continue
            
            task['status'] = 'completed'
        
        print(f"[INFO] Flaskå¯è§†åŒ–ï¼šæˆåŠŸç”Ÿæˆ {len(generated_charts)} ä¸ªå›¾è¡¨")
        
    except ImportError as e:
        print(f"[DEBUG] Flaskå¯è§†åŒ–ï¼šæ¨¡å—ä¸å¯ç”¨ - {e}")
    except Exception as e:
        print(f"[ERROR] Flaskå¯è§†åŒ–ï¼šå¤„ç†å¤±è´¥ - {e}")
    
    return generated_charts

# APIè·¯ç”±å®šä¹‰

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "healthy",
        "service": "DataProxy Flask API",
        "version": "2.0.0",
        "timestamp": time.time(),
        "initialized": global_state.initialized
    })

@app.route('/api/version', methods=['GET'])
def version_info():
    """ç‰ˆæœ¬ä¿¡æ¯ç«¯ç‚¹"""
    return jsonify({
        'version': '2.0.0',
        'build_date': '2024-12-19',
        'features': [
            'LLMé©±åŠ¨çš„æ™ºèƒ½æŸ¥è¯¢',
            'æ™ºèƒ½å›¾è¡¨ä»£ç ç”Ÿæˆ',
            'é“¶è¡Œä¸šåŠ¡ä¸“ä¸šåŒ–',
            'ä¸Šä¸‹æ–‡ç®¡ç†'
        ]
    })

@app.route('/', methods=['GET'])
def root():
    """æ ¹è·¯å¾„"""
    return jsonify({
        'message': 'DataProxy API Server',
        'version': '2.0.0',
        'endpoints': {
            'health': '/api/health',
            'version': '/api/version',
            'queries': '/api/v1/queries'
        }
    })

@app.route('/api/v1/queries/agent', methods=['POST'])
def agent_query():
    """
    æ™ºèƒ½AgentæŸ¥è¯¢ï¼ˆä½¿ç”¨Streamlitæ ¸å¿ƒé€»è¾‘ï¼‰

    è¯·æ±‚å‚æ•°:
    - query (str): ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
    - use_simple_query (bool, å¯é€‰): æ˜¯å¦ä½¿ç”¨ç®€å•æŸ¥è¯¢æ¨¡å¼ï¼Œé»˜è®¤ä¸ºFalse
        * False (é»˜è®¤): å¤æ‚æŸ¥è¯¢æ¨¡å¼ï¼Œå¼ºåˆ¶ä½¿ç”¨DataProxyå·¥å…·ï¼Œç¡®ä¿è¿”å›ç»“æ„åŒ–æ•°æ®å’Œå›¾è¡¨
        * True: ç®€å•æŸ¥è¯¢æ¨¡å¼ï¼Œè®©Agentè‡ªç”±é€‰æ‹©å·¥å…·ï¼Œå¯èƒ½åªè¿”å›æ–‡æœ¬å›ç­”
    - enable_decomposition (bool, å¯é€‰): æ˜¯å¦å¯ç”¨æŸ¥è¯¢åˆ†è§£ï¼Œé»˜è®¤ä¸ºTrueï¼ˆä»…åœ¨å¤æ‚æŸ¥è¯¢æ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰
        * True (é»˜è®¤): å¯ç”¨åˆ†è§£ï¼Œå°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­æŸ¥è¯¢ï¼Œè·å¾—å¤šç»´åº¦è¯¦ç»†åˆ†æ
        * False: ç¦ç”¨åˆ†è§£ï¼Œå°†æŸ¥è¯¢ä½œä¸ºå•ä¸€æŸ¥è¯¢å¤„ç†ï¼Œæé«˜å“åº”é€Ÿåº¦

    å“åº”æ ¼å¼:
    - success (bool): æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
    - agent_response (str): Agentçš„æ–‡æœ¬å›ç­”
    - tool_calls (list): å·¥å…·è°ƒç”¨è®°å½•
    - enhanced_insights (dict): å¢å¼ºæ´å¯Ÿï¼ˆæ•´åˆinsightså’Œstatisticsï¼‰
    - visualizations (list): å¯è§†åŒ–å›¾è¡¨
    - data_tables (dict): ç»“æ„åŒ–æ•°æ®è¡¨
    - insights (str): åŸå§‹æ´å¯Ÿï¼ˆå‘åå…¼å®¹ï¼‰
    - recommendations (str): åŸå§‹å»ºè®®ï¼ˆå‘åå…¼å®¹ï¼‰
    - statistics (dict): ç»Ÿè®¡åˆ†æç»“æœï¼ˆå‘åå…¼å®¹ï¼‰
    """
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'query' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘æŸ¥è¯¢å‚æ•°"
            }), 400

        query = data['query']
        # ğŸ†• æ–°å¢å‚æ•°ï¼šæ˜¯å¦ä½¿ç”¨ç®€å•æŸ¥è¯¢æ¨¡å¼
        use_simple_query = data.get('use_simple_query', False)  # é»˜è®¤ä¸ºFalseï¼Œèµ°å¤æ‚æŸ¥è¯¢
        # ğŸ†• æ–°å¢å‚æ•°ï¼šæ˜¯å¦å¯ç”¨æŸ¥è¯¢åˆ†è§£ï¼ˆä»…åœ¨å¤æ‚æŸ¥è¯¢æ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰
        enable_decomposition = data.get('enable_decomposition', True)  # é»˜è®¤ä¸ºTrueï¼Œå¯ç”¨åˆ†è§£

        print(f"[INFO] æ”¶åˆ°å¢å¼ºAgentæŸ¥è¯¢: {query}")
        print(f"[INFO] å…ƒæ•°æ®å¢å¼ºçŠ¶æ€: {global_state.metadata_enhanced}")
        print(f"[INFO] æŸ¥è¯¢æ¨¡å¼: {'ç®€å•æŸ¥è¯¢' if use_simple_query else 'å¤æ‚æŸ¥è¯¢ï¼ˆé»˜è®¤ï¼‰'}")
        if not use_simple_query:
            print(f"[INFO] æŸ¥è¯¢åˆ†è§£æ§åˆ¶: {'âœ… å¯ç”¨åˆ†è§£ï¼ˆå¤šç»´åº¦åˆ†æï¼‰' if enable_decomposition else 'âŒ ç¦ç”¨åˆ†è§£ï¼ˆå•ä¸€æŸ¥è¯¢æ¨¡å¼ï¼‰'}")

        # åˆ›å»ºcallback handlerï¼ˆæ¨¡ä»¿Streamlitï¼‰
        callback_handler = FlaskCallbackHandler()

        # ğŸ”§ æ ¹æ®å‚æ•°å†³å®šæŸ¥è¯¢æ¨¡å¼
        if use_simple_query:
            # ç®€å•æŸ¥è¯¢æ¨¡å¼ï¼šè®©Agentè‡ªç”±é€‰æ‹©å·¥å…·
            print(f"[DEBUG] ä½¿ç”¨ç®€å•æŸ¥è¯¢æ¨¡å¼")
            callback_handler.set_current_query(query)
            final_query = query
        else:
            # å¤æ‚æŸ¥è¯¢æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼šå¼ºåˆ¶ä½¿ç”¨DataProxyå·¥å…·
            print(f"[DEBUG] ä½¿ç”¨å¤æ‚æŸ¥è¯¢æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰")
            # ğŸ”¥ æ–°å¢ï¼šæ„å»ºåŒ…å«åˆ†è§£æ§åˆ¶å‚æ•°çš„æŸ¥è¯¢
            decomposition_instruction = "å¯ç”¨åˆ†è§£è¿›è¡Œå¤šç»´åº¦åˆ†æ" if enable_decomposition else "ç¦ç”¨åˆ†è§£ä½¿ç”¨å•ä¸€æŸ¥è¯¢æ¨¡å¼"
            final_query = f"è¯·ä½¿ç”¨DataProxyå·¥å…·åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼ˆ{decomposition_instruction}ï¼‰ï¼Œç¡®ä¿è¿”å›ç»“æ„åŒ–æ•°æ®å’Œå¯è§†åŒ–å›¾è¡¨ï¼š{query}"
            callback_handler.set_current_query(final_query)
            # ğŸ”¥ æ–°å¢ï¼šè®¾ç½®åˆ†è§£æ§åˆ¶å‚æ•°åˆ°callback handler
            callback_handler.enable_decomposition = enable_decomposition

        # æ¸…ç©ºä¹‹å‰çš„å›¾è¡¨ï¼ˆæ¨¡ä»¿Streamlité€»è¾‘ï¼‰
        global_state.simple_charts = []

        # ğŸ”¥ ä½¿ç”¨å¢å¼ºçš„æŸ¥è¯¢å¤„ç†æ–¹æ³•
        if not hasattr(global_state, 'dataproxy_tool') or not global_state.dataproxy_tool:
            return jsonify({
                "success": False,
                "error": "DataProxyå·¥å…·ä¸å¯ç”¨"
            }), 500

        try:
            # æ ¹æ®æŸ¥è¯¢æ¨¡å¼é€‰æ‹©åˆ†ææ¨¡å¼
            if use_simple_query:
                analysis_mode = "simple"
            else:
                analysis_mode = "detailed" if enable_decomposition else "auto"

            print(f"[DEBUG] ä½¿ç”¨åˆ†ææ¨¡å¼: {analysis_mode}")

            # ğŸ”¥ ä½¿ç”¨å¢å¼ºçš„æŸ¥è¯¢å¤„ç†æ–¹æ³•
            result = global_state.process_query_enhanced(query)

        except Exception as e:
            print(f"[ERROR] DataProxyå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "error": f"åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}"
            }), 500

        # ğŸ”¥ ç®€åŒ–çš„å“åº”å¤„ç†
        if not result.get('success', False):
            return jsonify({
                "success": False,
                "error": result.get('error', 'åˆ†æå¤±è´¥'),
                "agent_response": "æŠ±æ­‰ï¼Œåˆ†æè¿‡ç¨‹ä¸­é‡åˆ°äº†é—®é¢˜ã€‚",
                "tool_calls": [],
                "data_tables": {},
                "visualizations": [],
                "insights": "",
                "recommendations": "",
                "statistics": {}
            }), 500

        # æå–ç»“æœæ•°æ®
        data_tables = result.get('data_tables', {})
        insights = result.get('insights', [])
        statistics = result.get('statistics', {})
        visualization_data = result.get('visualization_data', {})

        # ğŸ”¥ æ„å»ºç®€åŒ–çš„å“åº”
        # ç”Ÿæˆç®€å•çš„agent_response
        agent_response = f"å·²å®Œæˆå¯¹æŸ¥è¯¢ã€Œ{query}ã€çš„åˆ†æ"
        if insights:
            agent_response += f"ï¼Œç”Ÿæˆäº† {len(insights)} æ¡æ´å¯Ÿ"
        if data_tables:
            agent_response += f"ï¼ŒåŒ…å« {len(data_tables)} ä¸ªæ•°æ®è¡¨"

        # æ„å»ºå·¥å…·è°ƒç”¨è®°å½•ï¼ˆæ¨¡æ‹Ÿï¼‰
        tool_calls = [{
            "tool_name": "simplified_dataproxy",
            "input_args": {"query": query, "analysis_mode": analysis_mode},
            "output": result,
            "success": True
        }]

        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "success": True,
            "agent_response": agent_response,
            "tool_calls": tool_calls,
            "data_tables": data_tables,
            "visualizations": [],  # ç®€åŒ–ç‰ˆæš‚ä¸æ”¯æŒå¯è§†åŒ–
            "insights": "\n".join(insights) if isinstance(insights, list) else str(insights),
            "recommendations": "",  # ç®€åŒ–ç‰ˆæš‚ä¸æ”¯æŒå»ºè®®
            "statistics": statistics,
            "conversation_id": None
        }

        return jsonify(response_data)

    except Exception as e:
        print(f"[ERROR] AgentæŸ¥è¯¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/queries/nl2sql', methods=['POST'])
def nl2sql_query():
    """NL2SQLæŸ¥è¯¢"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'query' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘æŸ¥è¯¢å‚æ•°"
            }), 400

        query = data['query']
        print(f"[INFO] æ”¶åˆ°NL2SQLæŸ¥è¯¢: {query}")

        # ä½¿ç”¨Agentçš„NL2SQLåŠŸèƒ½
        if hasattr(global_state.agent, 'nl2sql_tool'):
            result = global_state.agent.nl2sql_tool._run(query)
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨Agent
            async def run_nl2sql():
                return await global_state.agent.analyze(query, None)

            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(run_nl2sql())
            finally:
                loop.close()

        return jsonify({
            "success": True,
            "sql": result.get('sql', ''),
            "data": result.get('data', []),
            "columns": result.get('columns', []),
            "row_count": len(result.get('data', [])),
            "execution_time": result.get('execution_time', 0)
        })

    except Exception as e:
        print(f"[ERROR] NL2SQLæŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/databases', methods=['GET'])
def get_databases():
    """è·å–å¯ç”¨æ•°æ®åº“åˆ—è¡¨"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        databases = []
        for db_path, db_info in global_state.available_databases.items():
            # ğŸ”§ ä¿®å¤ï¼šåªè¿”å›çœŸå®å­˜åœ¨çš„æ•°æ®åº“æ–‡ä»¶
            if db_info.get('file_exists', True) and db_info.get('status') == 'available':
                databases.append({
                    "path": db_path,
                    "name": db_info.get('name', os.path.basename(db_path)),
                    "table_count": db_info.get('table_count', 0),
                    "description": db_info.get('description', ''),
                    "size": db_info.get('size', 0)
                })

        return jsonify({
            "success": True,
            "databases": databases,
            "current_database": global_state.current_database,
            "total_count": len(databases)
        })

    except Exception as e:
        print(f"[ERROR] è·å–æ•°æ®åº“åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/databases/switch', methods=['POST'])
def switch_database():
    """åˆ‡æ¢æ•°æ®åº“"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        print(f"[INFO] åˆ‡æ¢æ•°æ®åº“åˆ°: {database_path}")

        # æ‰§è¡Œæ•°æ®åº“åˆ‡æ¢
        success = global_state.unified_config.switch_database(database_path)

        if success:
            global_state.current_database = database_path

            # ï¿½ ä¿®å¤ï¼šæ›´æ–°å…¨å±€ç»Ÿä¸€é…ç½®
            try:
                from core_modules.config.unified_config import update_global_config_database
                update_global_config_database(database_path)
                print("âœ… å…¨å±€ç»Ÿä¸€é…ç½®å·²æ›´æ–°")
            except Exception as e:
                print(f"âš ï¸ å…¨å±€ç»Ÿä¸€é…ç½®æ›´æ–°å¤±è´¥: {e}")

            # ï¿½ğŸ”¥ é‡æ–°åˆå§‹åŒ–å…ƒæ•°æ®å¢å¼ºå™¨
            global_state._initialize_metadata_enhancer()

            # ğŸ”¥ é‡æ–°åˆå§‹åŒ–ç®€åŒ–çš„DataProxyå·¥å…·
            try:
                if UNIFIED_TOOLS_AVAILABLE:
                    global_state.dataproxy_tool = SimplifiedDataProxyTool()
                    print("âœ… ç®€åŒ–DataProxyå·¥å…·é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                else:
                    global_state.dataproxy_tool = None
                    print("âŒ ç»Ÿä¸€å·¥å…·ç³»ç»Ÿä¸å¯ç”¨")

                # æ¸…ç©ºå›¾è¡¨çŠ¶æ€
                global_state.simple_charts = []

                print(f"[INFO] å¢å¼ºæ•°æ®åº“åˆ‡æ¢æˆåŠŸ: {database_path}")

                # ğŸ”¥ æ„å»ºå¢å¼ºçš„å“åº”
                response = {
                    "success": True,
                    "message": "æ•°æ®åº“åˆ‡æ¢æˆåŠŸ",
                    "current_database": database_path,
                    "metadata_enhanced": global_state.metadata_enhanced
                }

                # å¦‚æœæ˜¯å…ƒæ•°æ®å¢å¼ºçš„ï¼Œæ·»åŠ é¢å¤–ä¿¡æ¯
                if (global_state.metadata_enhanced and
                    hasattr(global_state, 'metadata_aware_config') and
                    global_state.metadata_aware_config and
                    hasattr(global_state.metadata_aware_config, 'is_metadata_enhanced') and
                    global_state.metadata_aware_config.is_metadata_enhanced()):
                    response.update({
                        "metadata_info": {
                            "business_terms_count": len(global_state.metadata_aware_config.business_terms),
                            "field_mappings_count": len(global_state.metadata_aware_config.field_mappings),
                            "enhanced_features": [
                                "å­—æ®µä¸­æ–‡åæ˜ å°„",
                                "ä¸šåŠ¡è§„åˆ™è‡ªåŠ¨åº”ç”¨",
                                "æ•°æ®å­—å…¸å¢å¼º",
                                "æŸ¥è¯¢æ™ºèƒ½å»ºè®®"
                            ]
                        }
                    })

                return jsonify(response)
            except Exception as agent_error:
                print(f"[WARNING] Agenté‡æ–°åˆå§‹åŒ–å¤±è´¥: {agent_error}")
                return jsonify({
                    "success": True,
                    "message": "æ•°æ®åº“åˆ‡æ¢æˆåŠŸï¼Œä½†Agenté‡æ–°åˆå§‹åŒ–å¤±è´¥",
                    "current_database": database_path,
                    "warning": str(agent_error)
                })
        else:
            return jsonify({
                "success": False,
                "error": "æ•°æ®åº“åˆ‡æ¢å¤±è´¥"
            }), 400

    except Exception as e:
        print(f"[ERROR] æ•°æ®åº“åˆ‡æ¢å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts', methods=['GET'])
def list_contexts():
    """åˆ—å‡ºæ‰€æœ‰ä¸Šä¸‹æ–‡"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        contexts = global_state.file_manager.list_all_contexts()

        return jsonify({
            "success": True,
            "contexts": contexts,
            "total_count": len(contexts)
        })

    except Exception as e:
        print(f"[ERROR] åˆ—å‡ºä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "contexts": [],
            "total_count": 0
        }), 500

@app.route('/api/v1/status', methods=['GET'])
def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        status = {
            "service": "DataProxy Flask API",
            "version": "1.0.0",
            "initialized": global_state.initialized,
            "current_database": global_state.current_database,
            "available_databases_count": len(global_state.available_databases),
            "enhanced_visualization_available": ENHANCED_VIZ_AVAILABLE,
            "smart_statistics_available": SMART_STATS_AVAILABLE,
            "new_insights_available": NEW_INSIGHTS_AVAILABLE,  # ğŸ†• æ–°å¢æ–°æ´å¯Ÿåˆ†æçŠ¶æ€
            "enhanced_insights_available": ENHANCED_INSIGHTS_AVAILABLE,  # ä¿ç•™å¤‡ç”¨
            "components": {}
        }

        # æ£€æŸ¥å„ç»„ä»¶çŠ¶æ€
        try:
            status["components"]["unified_config"] = "âœ… Available" if global_state.unified_config else "âŒ Not initialized"
        except:
            status["components"]["unified_config"] = "âŒ Error"

        try:
            status["components"]["agent"] = "âœ… Available" if global_state.agent else "âŒ Not initialized"
        except:
            status["components"]["agent"] = "âŒ Error"

        try:
            status["components"]["context_manager"] = "âœ… Available" if global_state.context_manager else "âŒ Not initialized"
        except:
            status["components"]["context_manager"] = "âŒ Error"

        try:
            status["components"]["chart_system"] = "âœ… Available" if global_state.chart_system else "âŒ Not initialized"
        except:
            status["components"]["chart_system"] = "âŒ Error"

        # ğŸ†• æ£€æŸ¥æ™ºèƒ½ç»Ÿè®¡åˆ†ææ¨¡å—çŠ¶æ€
        try:
            status["components"]["smart_statistics"] = "âœ… Available" if SMART_STATS_AVAILABLE else "âŒ Not available"
        except:
            status["components"]["smart_statistics"] = "âŒ Error"

        # ğŸ†• æ£€æŸ¥æ–°æ´å¯Ÿåˆ†æçŠ¶æ€
        try:
            status["components"]["new_insights"] = "âœ… Available" if NEW_INSIGHTS_AVAILABLE else "âŒ Not available"
        except:
            status["components"]["new_insights"] = "âŒ Error"

        # æ£€æŸ¥å¢å¼ºæ´å¯Ÿç”Ÿæˆå™¨çŠ¶æ€ï¼ˆå¤‡ç”¨ï¼‰
        try:
            status["components"]["enhanced_insights"] = "âœ… Available" if ENHANCED_INSIGHTS_AVAILABLE else "âŒ Not available"
        except:
            status["components"]["enhanced_insights"] = "âŒ Error"

        if not ENHANCED_VIZ_AVAILABLE:
            status["enhanced_visualization_error"] = ENHANCED_VIZ_ERROR

        return jsonify(status)

    except Exception as e:
        return jsonify({
            "service": "DataProxy Flask API",
            "status": "error",
            "error": str(e)
        }), 500

@app.route('/api/v1/files/upload', methods=['POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                "success": False,
                "error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"
            }), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({
                "success": False,
                "error": "æ–‡ä»¶åä¸ºç©º"
            }), 400

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.db', '.sqlite', '.sqlite3', '.csv', '.xlsx', '.xls'}
        file_ext = os.path.splitext(file.filename)[1].lower()
        if file_ext not in allowed_extensions:
            return jsonify({
                "success": False,
                "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
            }), 400

        # è·å–ç”¨æˆ·æä¾›çš„é¢å¤–ä¿¡æ¯
        user_description = request.form.get('description', '')
        user_terms = request.form.get('business_terms', '')
        data_dictionary = request.form.get('data_dictionary', '')

        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        filename = secure_filename(file.filename)
        temp_file_path = os.path.join(temp_dir, filename)
        file.save(temp_file_path)

        print(f"[INFO] æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶è·¯å¾„: {temp_file_path}")

        # å¦‚æœæ˜¯CSVæˆ–Excelæ–‡ä»¶ï¼Œå…ˆè½¬æ¢ä¸ºSQLite
        if file_ext in {'.csv', '.xlsx', '.xls'}:
            print(f"[INFO] è½¬æ¢æ–‡ä»¶æ ¼å¼: {file_ext} -> SQLite")

            # ç”ŸæˆSQLiteæ–‡ä»¶è·¯å¾„
            sqlite_filename = os.path.splitext(filename)[0] + '.db'
            sqlite_path = os.path.join(temp_dir, sqlite_filename)

            # ä½¿ç”¨FileConverterè½¬æ¢
            converted_path = global_state.file_converter.convert_to_sqlite(temp_file_path, sqlite_path)

            # æ›´æ–°æ–‡ä»¶è·¯å¾„ä¸ºè½¬æ¢åçš„SQLiteæ–‡ä»¶
            temp_file_path = converted_path
            filename = sqlite_filename

        # æ„å»ºç”¨æˆ·æç¤º
        user_hints = {
            'description': user_description,
            'business_terms': user_terms,
            'data_dictionary': data_dictionary
        }

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¤„ç†æ–‡ä»¶
        context = global_state.context_manager.process_uploaded_file(temp_file_path, user_hints)

        if context:
            # ä¿å­˜ä¸Šä¸‹æ–‡é…ç½®
            config_file = global_state.file_manager.save_context(context)

            # å°†æ–‡ä»¶ç§»åŠ¨åˆ°æ•°æ®åº“ç›®å½•ï¼ˆå¯é€‰ï¼‰
            databases_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'databases')
            os.makedirs(databases_dir, exist_ok=True)

            final_db_path = os.path.join(databases_dir, filename)
            shutil.move(temp_file_path, final_db_path)

            # æ›´æ–°ä¸Šä¸‹æ–‡ä¸­çš„æ•°æ®åº“è·¯å¾„
            context.database_path = final_db_path
            global_state.file_manager.save_context(context)

            # åˆ·æ–°å¯ç”¨æ•°æ®åº“åˆ—è¡¨
            global_state.available_databases = global_state.unified_config.get_available_databases()

            return jsonify({
                "success": True,
                "message": "æ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†æˆåŠŸ",
                "database_path": final_db_path,
                "database_name": context.database_name,
                "database_type": context.database_type,
                "config_file": config_file,
                "context_summary": {
                    "business_terms_count": len(context.business_terms),
                    "field_mappings_count": len(context.field_mappings),
                    "tables_count": len(context.tables)
                }
            })
        else:
            return jsonify({
                "success": False,
                "error": "æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆä¸Šä¸‹æ–‡"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)
        except:
            pass

@app.route('/api/v1/files/intelligent-import', methods=['POST'])
def intelligent_data_import():
    """æ™ºèƒ½æ•°æ®å¯¼å…¥æ¥å£ - åŸºäºæ•°æ®å­—å…¸é©±åŠ¨çš„æ‰¹é‡æ•°æ®å¯¼å…¥"""
    if not INTELLIGENT_IMPORT_AVAILABLE:
        return jsonify({
            "success": False,
            "error": "æ™ºèƒ½æ•°æ®å¯¼å…¥åŠŸèƒ½ä¸å¯ç”¨",
            "details": INTELLIGENT_IMPORT_ERROR if 'INTELLIGENT_IMPORT_ERROR' in globals() else "æ¨¡å—æœªåŠ è½½"
        }), 503

    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ 
        if 'files' not in request.files:
            return jsonify({
                "success": False,
                "error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"
            }), 400

        files = request.files.getlist('files')
        if not files or all(file.filename == '' for file in files):
            return jsonify({
                "success": False,
                "error": "æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆæ–‡ä»¶"
            }), 400

        # è·å–è¾“å‡ºæ•°æ®åº“åç§°
        output_db_name = request.form.get('output_db_name', 'intelligent_import_result.db')
        if not output_db_name.endswith('.db'):
            output_db_name += '.db'

        # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        temp_dir = tempfile.mkdtemp()
        file_paths = []

        try:
            # ä¿å­˜æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶
            for file in files:
                if file.filename:
                    filename = secure_filename(file.filename)
                    file_path = os.path.join(temp_dir, filename)
                    file.save(file_path)
                    file_paths.append(file_path)

            if not file_paths:
                return jsonify({
                    "success": False,
                    "error": "æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶è¢«ä¿å­˜"
                }), 400

            # è®¾ç½®è¾“å‡ºæ•°æ®åº“è·¯å¾„
            databases_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'databases')
            os.makedirs(databases_dir, exist_ok=True)
            output_db_path = os.path.join(databases_dir, output_db_name)

            # åˆ›å»ºæ™ºèƒ½æ•°æ®å¯¼å…¥å™¨
            importer = IntelligentDataImporter()

            # æ‰§è¡Œæ‰¹é‡å¯¼å…¥
            print(f"[INFO] ğŸš€ å¼€å§‹æ™ºèƒ½æ•°æ®å¯¼å…¥ï¼Œå¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
            import_report = importer.process_batch_import(file_paths, output_db_path)

            # æ„å»ºå“åº”
            response = {
                "success": True,
                "message": "æ™ºèƒ½æ•°æ®å¯¼å…¥å®Œæˆ",
                "output_database": output_db_path,
                "output_database_name": output_db_name,
                "import_report": import_report,
                "processed_files": [os.path.basename(path) for path in file_paths]
            }

            # åˆ·æ–°å¯ç”¨æ•°æ®åº“åˆ—è¡¨
            global_state.available_databases = global_state.unified_config.get_available_databases()

            print(f"[INFO] âœ… æ™ºèƒ½æ•°æ®å¯¼å…¥æˆåŠŸ: {import_report['import_summary']['total_imported_rows']} æ¡è®°å½•")
            return jsonify(response)

        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        print(f"[ERROR] æ™ºèƒ½æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e),
            "error_type": type(e).__name__
        }), 500

@app.route('/api/v1/files/llm-intelligent-import', methods=['POST'])
def llm_intelligent_data_import():
    """LLMæ™ºèƒ½æ•°æ®å¯¼å…¥æ¥å£ - åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„çœŸæ­£æ™ºèƒ½åŒ–æ•°æ®åˆ†æå’Œå¯¼å…¥"""
    try:
        # æ£€æŸ¥LLMæ™ºèƒ½å¯¼å…¥å™¨æ˜¯å¦å¯ç”¨
        try:
            from core_modules.data_import import LLMIntelligentDataImporter
        except ImportError as e:
            return jsonify({
                "success": False,
                "error": "LLMæ™ºèƒ½æ•°æ®å¯¼å…¥åŠŸèƒ½ä¸å¯ç”¨",
                "details": f"å¯¼å…¥å¤±è´¥: {e}",
                "suggestion": "è¯·ç¡®ä¿å·²å®‰è£…langchainå’Œç›¸å…³ä¾èµ–"
            }), 503

        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚å‚æ•°
        data_source_dir = request.form.get('data_source_dir')
        data_dict_dir = request.form.get('data_dict_dir')
        output_db_name = request.form.get('output_db_name', 'llm_generated.db')
        api_key = request.form.get('api_key')  # å¯é€‰çš„APIå¯†é’¥

        # å‚æ•°éªŒè¯
        if not data_source_dir or not data_dict_dir:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦å‚æ•°",
                "required_params": ["data_source_dir", "data_dict_dir"],
                "provided_params": {
                    "data_source_dir": bool(data_source_dir),
                    "data_dict_dir": bool(data_dict_dir)
                }
            }), 400

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        project_root = os.path.dirname(os.path.dirname(__file__))
        full_data_source_dir = os.path.join(project_root, data_source_dir)
        full_data_dict_dir = os.path.join(project_root, data_dict_dir)

        if not os.path.exists(full_data_source_dir):
            return jsonify({
                "success": False,
                "error": f"æ•°æ®æºç›®å½•ä¸å­˜åœ¨: {data_source_dir}",
                "full_path": full_data_source_dir
            }), 400

        if not os.path.exists(full_data_dict_dir):
            return jsonify({
                "success": False,
                "error": f"æ•°æ®å­—å…¸ç›®å½•ä¸å­˜åœ¨: {data_dict_dir}",
                "full_path": full_data_dict_dir
            }), 400

        # è®¾ç½®è¾“å‡ºæ•°æ®åº“è·¯å¾„
        if not output_db_name.endswith('.db'):
            output_db_name += '.db'

        databases_dir = os.path.join(project_root, 'databases')
        os.makedirs(databases_dir, exist_ok=True)
        output_db_path = os.path.join(databases_dir, output_db_name)

        # åˆ›å»ºLLMæ™ºèƒ½æ•°æ®å¯¼å…¥å™¨
        print(f"[INFO] ğŸ§  å¼€å§‹LLMæ™ºèƒ½æ•°æ®å¯¼å…¥")
        print(f"[INFO] æ•°æ®æºç›®å½•: {full_data_source_dir}")
        print(f"[INFO] æ•°æ®å­—å…¸ç›®å½•: {full_data_dict_dir}")
        print(f"[INFO] è¾“å‡ºæ•°æ®åº“: {output_db_path}")

        importer = LLMIntelligentDataImporter(api_key=api_key)

        # æ‰§è¡ŒLLMæ™ºèƒ½å¯¼å…¥
        import_report = importer.process_batch_import(
            data_source_dir=full_data_source_dir,
            data_dict_dir=full_data_dict_dir,
            output_db_path=output_db_path
        )

        if import_report.get('success'):
            # æ„å»ºæˆåŠŸå“åº”
            response = {
                "success": True,
                "message": "LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å®Œæˆ",
                "output_database": output_db_path,
                "output_database_name": output_db_name,
                "import_report": import_report,
                "llm_analysis_summary": import_report.get('llm_analysis_summary', {}),
                "processing_summary": import_report.get('processing_summary', {}),
                "generated_business_terms": import_report.get('generated_business_terms', []),
                "recommendations": import_report.get('recommendations', [])
            }

            # åˆ·æ–°å¯ç”¨æ•°æ®åº“åˆ—è¡¨
            global_state.available_databases = global_state.unified_config.get_available_databases()

            print(f"[INFO] âœ… LLMæ™ºèƒ½æ•°æ®å¯¼å…¥æˆåŠŸ")
            print(f"[INFO] åˆ›å»ºè¡¨: {import_report.get('processing_summary', {}).get('total_tables_created', 0)} ä¸ª")
            print(f"[INFO] å¯¼å…¥æ•°æ®: {import_report.get('processing_summary', {}).get('total_imported_rows', 0)} è¡Œ")

            return jsonify(response)
        else:
            # å¯¼å…¥å¤±è´¥
            return jsonify({
                "success": False,
                "error": "LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å¤±è´¥",
                "details": import_report.get('error', 'Unknown error'),
                "execution_time": import_report.get('execution_time', 0)
            }), 500

    except Exception as e:
        print(f"[ERROR] LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e),
            "error_type": type(e).__name__,
            "suggestion": "è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®å’Œç½‘ç»œè¿æ¥"
        }), 500

@app.route('/api/v1/files/pure-llm-import', methods=['POST'])
def pure_llm_intelligent_import():
    """çº¯LLMé©±åŠ¨çš„æ™ºèƒ½æ•°æ®å¯¼å…¥æ¥å£ - å®Œå…¨åŸºäºLLMçš„é›¶è§„åˆ™ç¼–ç æ•°æ®åˆ†æå’Œå¯¼å…¥"""
    try:
        # æ£€æŸ¥çº¯LLMæ™ºèƒ½å¯¼å…¥å™¨æ˜¯å¦å¯ç”¨
        try:
            from core_modules.data_import import IntelligentDataImporter
        except ImportError as e:
            return jsonify({
                "success": False,
                "error": "çº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥åŠŸèƒ½ä¸å¯ç”¨",
                "details": f"å¯¼å…¥å¤±è´¥: {e}",
                "suggestion": "è¯·ç¡®ä¿å·²å®‰è£…langchainå’Œç›¸å…³ä¾èµ–ï¼Œå¹¶é…ç½®DEEPSEEK_API_KEY"
            }), 503

        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚å‚æ•°
        data_source_dir = request.form.get('data_source_dir')
        data_dict_dir = request.form.get('data_dict_dir')
        output_db_name = request.form.get('output_db_name', 'pure_llm_generated.db')
        api_key = request.form.get('api_key')  # APIå¯†é’¥

        # æ£€æŸ¥APIå¯†é’¥
        if not api_key:
            api_key = os.getenv('DEEPSEEK_API_KEY')

        if not api_key:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘APIå¯†é’¥",
                "details": "çº¯LLMç³»ç»Ÿéœ€è¦DeepSeek APIå¯†é’¥",
                "suggestion": "è¯·åœ¨è¯·æ±‚ä¸­æä¾›api_keyå‚æ•°æˆ–è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡"
            }), 400

        # å‚æ•°éªŒè¯
        if not data_source_dir or not data_dict_dir:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦å‚æ•°",
                "required_params": ["data_source_dir", "data_dict_dir"],
                "provided_params": {
                    "data_source_dir": bool(data_source_dir),
                    "data_dict_dir": bool(data_dict_dir)
                }
            }), 400

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        project_root = os.path.dirname(os.path.dirname(__file__))
        full_data_source_dir = os.path.join(project_root, data_source_dir)
        full_data_dict_dir = os.path.join(project_root, data_dict_dir)

        if not os.path.exists(full_data_source_dir):
            return jsonify({
                "success": False,
                "error": f"æ•°æ®æºç›®å½•ä¸å­˜åœ¨: {data_source_dir}",
                "full_path": full_data_source_dir
            }), 400

        if not os.path.exists(full_data_dict_dir):
            return jsonify({
                "success": False,
                "error": f"æ•°æ®å­—å…¸ç›®å½•ä¸å­˜åœ¨: {data_dict_dir}",
                "full_path": full_data_dict_dir
            }), 400

        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶è·¯å¾„
        file_paths = []

        # æ”¶é›†æ•°æ®æºæ–‡ä»¶
        for file_name in os.listdir(full_data_source_dir):
            if file_name.endswith(('.xlsx', '.xls', '.csv')):
                file_paths.append(os.path.join(full_data_source_dir, file_name))

        # æ”¶é›†æ•°æ®å­—å…¸æ–‡ä»¶
        for file_name in os.listdir(full_data_dict_dir):
            if file_name.endswith(('.xlsx', '.xls', '.csv')):
                file_paths.append(os.path.join(full_data_dict_dir, file_name))

        if not file_paths:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°å¯å¤„ç†çš„æ–‡ä»¶",
                "details": "æ•°æ®æºå’Œæ•°æ®å­—å…¸ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°.xlsx, .xlsæˆ–.csvæ–‡ä»¶"
            }), 400

        # è®¾ç½®è¾“å‡ºæ•°æ®åº“è·¯å¾„
        if not output_db_name.endswith('.db'):
            output_db_name += '.db'

        databases_dir = os.path.join(project_root, 'databases')
        os.makedirs(databases_dir, exist_ok=True)
        output_db_path = os.path.join(databases_dir, output_db_name)

        # åˆ›å»ºçº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å™¨
        print(f"[INFO] ğŸ§  å¼€å§‹çº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥")
        print(f"[INFO] æ•°æ®æºç›®å½•: {full_data_source_dir}")
        print(f"[INFO] æ•°æ®å­—å…¸ç›®å½•: {full_data_dict_dir}")
        print(f"[INFO] å‘ç°æ–‡ä»¶: {len(file_paths)} ä¸ª")
        print(f"[INFO] è¾“å‡ºæ•°æ®åº“: {output_db_path}")
        print(f"[INFO] â³ æ³¨æ„: çº¯LLMåˆ†æå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")

        importer = IntelligentDataImporter(api_key=api_key)

        # æ‰§è¡Œçº¯LLMæ™ºèƒ½å¯¼å…¥
        import_report = importer.process_batch_import(file_paths, output_db_path)

        if import_report.get('success'):
            # æ„å»ºæˆåŠŸå“åº”
            response = {
                "success": True,
                "message": "çº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å®Œæˆ",
                "output_database": output_db_path,
                "output_database_name": output_db_name,
                "import_report": import_report,
                "processing_summary": import_report.get('processing_summary', {}),
                "llm_comprehensive_analysis": import_report.get('llm_comprehensive_analysis', {}),
                "business_intelligence": import_report.get('business_intelligence', {}),
                "execution_time": import_report.get('execution_time', 0),
                "processed_files": [os.path.basename(fp) for fp in file_paths]
            }

            # åˆ·æ–°å¯ç”¨æ•°æ®åº“åˆ—è¡¨
            global_state.available_databases = global_state.unified_config.get_available_databases()

            print(f"[INFO] âœ… çº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥æˆåŠŸ")
            processing_summary = import_report.get('processing_summary', {})
            print(f"[INFO] å¤„ç†æ–‡ä»¶: {processing_summary.get('total_files_processed', 0)} ä¸ª")
            print(f"[INFO] åˆ›å»ºè¡¨: {processing_summary.get('total_tables_created', 0)} ä¸ª")
            print(f"[INFO] å¯¼å…¥æ•°æ®: {processing_summary.get('total_imported_rows', 0)} è¡Œ")
            print(f"[INFO] LLMåˆ†ææˆåŠŸç‡: {processing_summary.get('llm_analysis_success_rate', 0):.1%}")

            return jsonify(response)
        else:
            # å¯¼å…¥å¤±è´¥
            return jsonify({
                "success": False,
                "error": "çº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å¤±è´¥",
                "details": import_report.get('error', 'Unknown error'),
                "execution_time": import_report.get('execution_time', 0)
            }), 500

    except Exception as e:
        print(f"[ERROR] çº¯LLMæ™ºèƒ½æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e),
            "error_type": type(e).__name__,
            "suggestion": "è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ã€ç½‘ç»œè¿æ¥å’Œæ–‡ä»¶æ ¼å¼"
        }), 500

@app.route('/api/v1/contexts', methods=['POST'])
def get_context_details():
    """è·å–ç‰¹å®šæ•°æ®åº“çš„ä¸Šä¸‹æ–‡è¯¦æƒ…"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        print(f"[DEBUG] è·å–ä¸Šä¸‹æ–‡è¯¦æƒ…: {database_path}")

        # åŠ è½½ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)

        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        context_dict = global_state.file_manager._context_to_dict(context)

        return jsonify({
            "success": True,
            "context": context_dict
        })

    except Exception as e:
        print(f"[ERROR] è·å–ä¸Šä¸‹æ–‡è¯¦æƒ…å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts', methods=['PUT'])
def update_context():
    """æ›´æ–°ä¸Šä¸‹æ–‡é…ç½®"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        print(f"[DEBUG] æ›´æ–°ä¸Šä¸‹æ–‡: {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # ğŸ”§ ä¿®å¤ï¼šæ”¯æŒå®Œæ•´çš„ä¸Šä¸‹æ–‡é…ç½®æ›´æ–°
        # åŸºæœ¬ä¿¡æ¯æ›´æ–°
        if 'description' in data:
            context.description = data['description']
        if 'database_type' in data:
            context.database_type = data['database_type']

        # ä¸šåŠ¡æœ¯è¯­æ›´æ–°ï¼ˆé€šç”¨ï¼‰
        if 'business_terms' in data:
            context.business_terms = data['business_terms']

        # å­—æ®µæ˜ å°„æ›´æ–°ï¼ˆé€šç”¨ï¼‰
        if 'field_mappings' in data:
            context.field_mappings = data['field_mappings']

        # ğŸ†• æ•°æ®åº“ç‰¹å®šé…ç½®æ›´æ–°
        if 'database_specific_business_terms' in data:
            context.database_specific_business_terms = data['database_specific_business_terms']

        if 'database_specific_field_mappings' in data:
            context.database_specific_field_mappings = data['database_specific_field_mappings']

        if 'database_specific_query_scopes' in data:
            context.database_specific_query_scopes = data['database_specific_query_scopes']

        # è¡¨å…³ç³»æ›´æ–°
        if 'relationships' in data:
            context.relationships = data['relationships']

        # è¡¨ç»“æ„æ›´æ–°ï¼ˆé€šå¸¸ä¸å»ºè®®æ‰‹åŠ¨ä¿®æ”¹ï¼Œä½†æä¾›æ¥å£ï¼‰
        if 'tables' in data:
            context.tables = data['tables']

        print(f"[DEBUG] ä¸Šä¸‹æ–‡æ›´æ–°é¡¹ç›®: {list(data.keys())}")

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": "ä¸Šä¸‹æ–‡æ›´æ–°æˆåŠŸ"
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜ä¸Šä¸‹æ–‡å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ›´æ–°ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/<path:database_path>', methods=['DELETE'])
def delete_context(database_path):
    """åˆ é™¤ä¸Šä¸‹æ–‡é…ç½®"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
        config_file = global_state.file_manager._find_config_file(database_path)

        if not config_file:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶"
            }), 404

        # åˆ é™¤é…ç½®æ–‡ä»¶
        os.remove(config_file)

        return jsonify({
            "success": True,
            "message": "ä¸Šä¸‹æ–‡é…ç½®å·²åˆ é™¤"
        })

    except Exception as e:
        print(f"[ERROR] åˆ é™¤ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/business-terms', methods=['GET'])
def get_business_terms():
    """è·å–ä¸šåŠ¡æœ¯è¯­åˆ—è¡¨"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚å‚æ•°
        database_path = request.args.get('database_path')
        if not database_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        print(f"[DEBUG] è·å–ä¸šåŠ¡æœ¯è¯­: {database_path}")

        # åŠ è½½ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # åˆå¹¶é€šç”¨ä¸šåŠ¡æœ¯è¯­å’Œæ•°æ®åº“ç‰¹å®šä¸šåŠ¡æœ¯è¯­
        all_terms = {}

        # æ·»åŠ é€šç”¨ä¸šåŠ¡æœ¯è¯­
        if hasattr(context, 'business_terms') and context.business_terms:
            for term_name, term_data in context.business_terms.items():
                all_terms[term_name] = {
                    **term_data,
                    "term_type": "general"
                }

        # æ·»åŠ æ•°æ®åº“ç‰¹å®šä¸šåŠ¡æœ¯è¯­
        if hasattr(context, 'database_specific_business_terms') and context.database_specific_business_terms:
            for term_name, term_data in context.database_specific_business_terms.items():
                all_terms[term_name] = {
                    **term_data,
                    "term_type": "database_specific"
                }

        return jsonify({
            "success": True,
            "business_terms": all_terms,
            "total_count": len(all_terms)
        })

    except Exception as e:
        print(f"[ERROR] è·å–ä¸šåŠ¡æœ¯è¯­å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/business-terms/<term_name>', methods=['GET'])
def get_business_term(term_name):
    """è·å–å•ä¸ªä¸šåŠ¡æœ¯è¯­è¯¦æƒ…"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚å‚æ•°
        database_path = request.args.get('database_path')
        if not database_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        print(f"[DEBUG] è·å–ä¸šåŠ¡æœ¯è¯­è¯¦æƒ…: {term_name} in {database_path}")

        # åŠ è½½ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æŸ¥æ‰¾æœ¯è¯­
        term_data = None
        term_type = None

        # å…ˆåœ¨é€šç”¨ä¸šåŠ¡æœ¯è¯­ä¸­æŸ¥æ‰¾
        if hasattr(context, 'business_terms') and context.business_terms and term_name in context.business_terms:
            term_data = context.business_terms[term_name]
            term_type = "general"

        # å†åœ¨æ•°æ®åº“ç‰¹å®šä¸šåŠ¡æœ¯è¯­ä¸­æŸ¥æ‰¾
        elif hasattr(context, 'database_specific_business_terms') and context.database_specific_business_terms and term_name in context.database_specific_business_terms:
            term_data = context.database_specific_business_terms[term_name]
            term_type = "database_specific"

        if not term_data:
            return jsonify({
                "success": False,
                "error": f"æœªæ‰¾åˆ°ä¸šåŠ¡æœ¯è¯­: {term_name}"
            }), 404

        return jsonify({
            "success": True,
            "term_name": term_name,
            "term_data": {
                **term_data,
                "term_type": term_type
            }
        })

    except Exception as e:
        print(f"[ERROR] è·å–ä¸šåŠ¡æœ¯è¯­è¯¦æƒ…å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/business-terms', methods=['POST'])
def add_business_term():
    """æ·»åŠ æ–°çš„ä¸šåŠ¡æœ¯è¯­"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        term_name = data.get('term_name')
        term_data = data.get('term_data')
        term_type = data.get('term_type', 'database_specific')  # é»˜è®¤ä¸ºæ•°æ®åº“ç‰¹å®šæœ¯è¯­

        if not term_name or not term_data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘term_nameæˆ–term_dataå‚æ•°"
            }), 400

        print(f"[DEBUG] æ·»åŠ ä¸šåŠ¡æœ¯è¯­: {term_name} ({term_type}) in {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æ£€æŸ¥æœ¯è¯­æ˜¯å¦å·²å­˜åœ¨
        term_exists = False
        if hasattr(context, 'business_terms') and context.business_terms and term_name in context.business_terms:
            term_exists = True
        elif hasattr(context, 'database_specific_business_terms') and context.database_specific_business_terms and term_name in context.database_specific_business_terms:
            term_exists = True

        if term_exists:
            return jsonify({
                "success": False,
                "error": f"ä¸šåŠ¡æœ¯è¯­ '{term_name}' å·²å­˜åœ¨"
            }), 409

        # æ·»åŠ æœ¯è¯­
        if term_type == "general":
            if not hasattr(context, 'business_terms') or context.business_terms is None:
                context.business_terms = {}
            context.business_terms[term_name] = term_data
        else:  # database_specific
            if not hasattr(context, 'database_specific_business_terms') or context.database_specific_business_terms is None:
                context.database_specific_business_terms = {}
            context.database_specific_business_terms[term_name] = term_data

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": f"ä¸šåŠ¡æœ¯è¯­ '{term_name}' æ·»åŠ æˆåŠŸ",
                "term_name": term_name,
                "term_type": term_type
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜ä¸šåŠ¡æœ¯è¯­å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ·»åŠ ä¸šåŠ¡æœ¯è¯­å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/business-terms', methods=['PUT'])
def update_business_terms():
    """æ›´æ–°ä¸šåŠ¡æœ¯è¯­é…ç½®"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        print(f"[DEBUG] æ›´æ–°ä¸šåŠ¡æœ¯è¯­: {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æ›´æ–°ä¸šåŠ¡æœ¯è¯­
        if 'business_terms' in data:
            if not hasattr(context, 'database_specific_business_terms') or context.database_specific_business_terms is None:
                context.database_specific_business_terms = {}
            context.database_specific_business_terms.update(data['business_terms'])

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": "ä¸šåŠ¡æœ¯è¯­æ›´æ–°æˆåŠŸ",
                "updated_terms": list(data.get('business_terms', {}).keys())
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜ä¸šåŠ¡æœ¯è¯­å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ›´æ–°ä¸šåŠ¡æœ¯è¯­å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/business-terms/<term_name>', methods=['PUT'])
def update_business_term(term_name):
    """æ›´æ–°å•ä¸ªä¸šåŠ¡æœ¯è¯­"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        term_data = data.get('term_data')
        term_type = data.get('term_type', 'database_specific')

        if not term_data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘term_dataå‚æ•°"
            }), 400

        print(f"[DEBUG] æ›´æ–°ä¸šåŠ¡æœ¯è¯­: {term_name} ({term_type}) in {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æŸ¥æ‰¾å¹¶æ›´æ–°æœ¯è¯­
        term_found = False

        if term_type == "general":
            if hasattr(context, 'business_terms') and context.business_terms and term_name in context.business_terms:
                context.business_terms[term_name] = term_data
                term_found = True
        else:  # database_specific
            if hasattr(context, 'database_specific_business_terms') and context.database_specific_business_terms and term_name in context.database_specific_business_terms:
                context.database_specific_business_terms[term_name] = term_data
                term_found = True

        if not term_found:
            return jsonify({
                "success": False,
                "error": f"æœªæ‰¾åˆ°ä¸šåŠ¡æœ¯è¯­: {term_name}"
            }), 404

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": f"ä¸šåŠ¡æœ¯è¯­ '{term_name}' æ›´æ–°æˆåŠŸ",
                "term_name": term_name,
                "term_type": term_type
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜ä¸šåŠ¡æœ¯è¯­å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ›´æ–°ä¸šåŠ¡æœ¯è¯­å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/business-terms/<term_name>', methods=['DELETE'])
def delete_business_term(term_name):
    """åˆ é™¤å•ä¸ªä¸šåŠ¡æœ¯è¯­"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚å‚æ•°
        database_path = request.args.get('database_path')
        if not database_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        print(f"[DEBUG] åˆ é™¤ä¸šåŠ¡æœ¯è¯­: {term_name} in {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æŸ¥æ‰¾å¹¶åˆ é™¤æœ¯è¯­
        term_found = False
        term_type = None

        # å…ˆåœ¨é€šç”¨ä¸šåŠ¡æœ¯è¯­ä¸­æŸ¥æ‰¾
        if hasattr(context, 'business_terms') and context.business_terms and term_name in context.business_terms:
            del context.business_terms[term_name]
            term_found = True
            term_type = "general"

        # å†åœ¨æ•°æ®åº“ç‰¹å®šä¸šåŠ¡æœ¯è¯­ä¸­æŸ¥æ‰¾
        elif hasattr(context, 'database_specific_business_terms') and context.database_specific_business_terms and term_name in context.database_specific_business_terms:
            del context.database_specific_business_terms[term_name]
            term_found = True
            term_type = "database_specific"

        if not term_found:
            return jsonify({
                "success": False,
                "error": f"æœªæ‰¾åˆ°ä¸šåŠ¡æœ¯è¯­: {term_name}"
            }), 404

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": f"ä¸šåŠ¡æœ¯è¯­ '{term_name}' åˆ é™¤æˆåŠŸ",
                "term_name": term_name,
                "term_type": term_type
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜ä¸Šä¸‹æ–‡å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] åˆ é™¤ä¸šåŠ¡æœ¯è¯­å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/field-mappings', methods=['PUT'])
def update_field_mappings():
    """æ›´æ–°å­—æ®µæ˜ å°„é…ç½®"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        print(f"[DEBUG] æ›´æ–°å­—æ®µæ˜ å°„: {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æ›´æ–°å­—æ®µæ˜ å°„
        if 'field_mappings' in data:
            if not hasattr(context, 'database_specific_field_mappings') or context.database_specific_field_mappings is None:
                context.database_specific_field_mappings = {}
            context.database_specific_field_mappings.update(data['field_mappings'])

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": "å­—æ®µæ˜ å°„æ›´æ–°æˆåŠŸ",
                "updated_fields": list(data.get('field_mappings', {}).keys())
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜å­—æ®µæ˜ å°„å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ›´æ–°å­—æ®µæ˜ å°„å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/contexts/query-scopes', methods=['PUT'])
def update_query_scopes():
    """æ›´æ–°æŸ¥è¯¢èŒƒå›´è§„åˆ™é…ç½®"""
    try:
        # ç¡®ä¿å…¨å±€çŠ¶æ€å·²åˆå§‹åŒ–
        if not global_state.initialized:
            success = global_state.initialize()
            if not success:
                return jsonify({
                    "success": False,
                    "error": "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
                }), 500

        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data or 'database_path' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘database_pathå‚æ•°"
            }), 400

        database_path = data['database_path']
        print(f"[DEBUG] æ›´æ–°æŸ¥è¯¢èŒƒå›´è§„åˆ™: {database_path}")

        # åŠ è½½ç°æœ‰ä¸Šä¸‹æ–‡
        context = global_state.file_manager.load_context(database_path)
        if not context:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¸‹æ–‡ä¿¡æ¯"
            }), 404

        # æ›´æ–°æŸ¥è¯¢èŒƒå›´è§„åˆ™
        if 'query_scopes' in data:
            if not hasattr(context, 'database_specific_query_scopes') or context.database_specific_query_scopes is None:
                context.database_specific_query_scopes = []
            context.database_specific_query_scopes = data['query_scopes']

        # ä¿å­˜ä¸Šä¸‹æ–‡
        success = global_state.file_manager.save_context(context)
        if success:
            return jsonify({
                "success": True,
                "message": "æŸ¥è¯¢èŒƒå›´è§„åˆ™æ›´æ–°æˆåŠŸ",
                "updated_scopes_count": len(data.get('query_scopes', []))
            })
        else:
            return jsonify({
                "success": False,
                "error": "ä¿å­˜æŸ¥è¯¢èŒƒå›´è§„åˆ™å¤±è´¥"
            }), 500

    except Exception as e:
        print(f"[ERROR] æ›´æ–°æŸ¥è¯¢èŒƒå›´è§„åˆ™å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# ğŸ”¥ æ–°å¢ï¼šå…ƒæ•°æ®æ„ŸçŸ¥APIç«¯ç‚¹
@app.route('/api/v1/metadata/info', methods=['GET'])
def get_metadata_info():
    """è·å–å½“å‰æ•°æ®åº“çš„å…ƒæ•°æ®ä¿¡æ¯"""
    try:
        if not global_state.initialized:
            return jsonify({
                "success": False,
                "error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"
            }), 500

        if not global_state.current_database:
            return jsonify({
                "success": False,
                "error": "æ²¡æœ‰é€‰æ‹©æ•°æ®åº“"
            }), 400

        response = {
            "success": True,
            "current_database": global_state.current_database,
            "metadata_enhanced": global_state.metadata_enhanced
        }

        # å¦‚æœæ˜¯å…ƒæ•°æ®å¢å¼ºçš„ï¼Œæä¾›è¯¦ç»†ä¿¡æ¯
        if (global_state.metadata_enhanced and
            hasattr(global_state, 'metadata_aware_config') and
            global_state.metadata_aware_config and
            hasattr(global_state.metadata_aware_config, 'is_metadata_enhanced') and
            global_state.metadata_aware_config.is_metadata_enhanced()):
            response.update({
                "metadata_details": {
                    "business_terms_count": len(global_state.metadata_aware_config.business_terms),
                    "field_mappings_count": len(global_state.metadata_aware_config.field_mappings),
                    "data_dictionary_tables": len(getattr(global_state.metadata_aware_config, 'data_dictionary_cache', {})),
                    "query_rules_count": len(global_state.metadata_aware_config.query_scope_rules)
                }
            })

        return jsonify(response)

    except Exception as e:
        print(f"[ERROR] è·å–å…ƒæ•°æ®ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/v1/metadata/field-suggestions', methods=['POST'])
def get_field_suggestions():
    """è·å–å­—æ®µå»ºè®®"""
    try:
        if not hasattr(global_state, 'metadata_enhancer') or not global_state.metadata_enhancer:
            return jsonify({
                "success": False,
                "error": "å…ƒæ•°æ®å¢å¼ºå™¨ä¸å¯ç”¨"
            }), 400

        data = request.get_json()
        if not data or 'partial_field_name' not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘partial_field_nameå‚æ•°"
            }), 400

        partial_field_name = data['partial_field_name']
        suggestions = global_state.metadata_enhancer.get_field_suggestions(partial_field_name)

        return jsonify({
            "success": True,
            "suggestions": suggestions
        })

    except Exception as e:
        print(f"[ERROR] è·å–å­—æ®µå»ºè®®å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

def cleanup_on_exit():
    """ä¼˜é›…å…³é—­å¤„ç†"""
    print("\nğŸ”„ æ­£åœ¨ä¼˜é›…å…³é—­æœåŠ¡å™¨...")
    try:
        if hasattr(global_state, 'cleanup'):
            global_state.cleanup()
        print("âœ… æœåŠ¡å™¨å·²å®‰å…¨å…³é—­")
    except Exception as e:
        print(f"âš ï¸ å…³é—­æ—¶å‡ºç°è­¦å‘Š: {e}")

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    print(f"\nğŸ“¡ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡å…³é—­æœåŠ¡å™¨...")
    cleanup_on_exit()
    sys.exit(0)

if __name__ == '__main__':
    print("ğŸš€ DataProxy API æœåŠ¡å™¨å¯åŠ¨ä¸­...")

    # ç®€åŒ–çŠ¶æ€æ˜¾ç¤º
    llm_status = "âœ…" if os.getenv('DEEPSEEK_API_KEY') else "âŒ"
    print(f"ğŸ“Š LLMæ™ºèƒ½æŸ¥è¯¢: {llm_status} | å¯è§†åŒ–: âœ… | æ•°æ®åˆ†æ: âœ…")

    # æ³¨å†Œä¼˜é›…å…³é—­å¤„ç†
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    atexit.register(cleanup_on_exit)

    # åˆå§‹åŒ–å…¨å±€çŠ¶æ€
    success = global_state.initialize()
    if success:
        debug_mode = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
        port = int(os.getenv('FLASK_PORT', '8000'))
        print(f"ğŸŒ æœåŠ¡å™¨è¿è¡Œåœ¨: http://localhost:{port}")
        print(f"ğŸ“Š æ•°æ®åº“: {global_state.current_database or 'æœªè¿æ¥'}")

        try:
            app.run(host='0.0.0.0', port=port, debug=debug_mode)
        except OSError as e:
            if "Address already in use" in str(e):
                print(f"âŒ ç«¯å£ {port} å·²è¢«å ç”¨ï¼Œå°è¯•ä½¿ç”¨ç«¯å£ {port + 1}")
                try:
                    app.run(host='0.0.0.0', port=port + 1, debug=debug_mode)
                except Exception as e2:
                    print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e2}")
                    sys.exit(1)
            else:
                print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
                sys.exit(1)


